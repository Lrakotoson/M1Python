{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from armining import *\n",
    "from io_utils import *\n",
    "from graphs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario 1 \n",
    "On suppose ici qu'à des fins d'études statistiques, une chaîne de restauration rapide a enregistré un échantillon de 1000 menus commandés par ses clients sur ses bornes interactives de commande. Cet échantillon est enregistré dans le fichier `dataQuestion1/menus.txt` dont chaque ligne donne un identifiant de la commande suivi de la liste des produits choisis séparés par des virgules. Vous pouvez récupérer ces informations sous forme d'un dictionnaire en utilisant la fonction `read_txt_to_dic()` du module `io_utils`: les clés de ce dictionnaire sont les identifiants de chaque commande, et les valeurs, les listes des produits composant chaque menu commandé.\n",
    "\n",
    "D'autre part, la chaine de restaurant a mené une enquête anonyme auprès de ses clients pour récolter leur appréciation des produits proposés, sur une échelle de 1 à 5. La note moyenne obtenue par chaque produit est répertoriée dans le fichier `dataQuestion1/notes_moyennes.txt` avec sur chaque ligne, le nom du produit suivi de sa note moyenne.\n",
    "\n",
    "La chaîne de restaurants souhaiterait proposer à partir de ces informations une recommandation **personnalisée** sur ses bornes interactives de commande. Pour donner un peu de fiabilité aux recommandations et donc ne pas trop agacer les clients avec de mauvaises propositions, on voudrait que la recommandation d'un produit soit correcte au moins une fois sur deux en moyenne, et que l'association du produit recommandé et des produits déjà choisis ait été rencontrée dans au moins 5% des menus enregistrés lors de l'étude statistique. Dans le cas contraire, on estime que la recommandation ne sera pas assez fiable et on préfère ne rien recommander à l'utilisateur sur la borne interactive.\n",
    "\n",
    "Avec ces contraintes, écrire le code permettant d'afficher le ou les produits que vous recommanderiez sur la borne interactive à un client dans les deux cas suivants:\n",
    "\n",
    "- l'utilisateur a déjà choisi les produits `Salade` et `Eau`\n",
    "- l'utilisateur a déjà choisi les produits `Wrap` et `Potatoes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "Recommendation for Salade and Eau with support of 50 and 0.5 confidence:\n",
      "{'Eau', 'Salade'} -> {'Nuggets'}\n",
      "===========================================================================\n",
      "Recommendation for Wrap and Potatoes with support of 50 and 0.5 confidence:\n",
      "No recommendation\n"
     ]
    }
   ],
   "source": [
    "history = list(map(ItemSet, read_txt_to_dic(\"dataQuestion1/menus.txt\").values()))\n",
    "support = int(len(history)*.05)\n",
    "conf = .5\n",
    "for ant1, ant2 in [(\"Salade\", \"Eau\"), (\"Wrap\", \"Potatoes\")]:\n",
    "    print(f\"{'='*75}\\nRecommendation for {ant1} and {ant2} with support of {support} and {conf} confidence:\")\n",
    "    ar = lambda x:ant1 in x.antecedent and ant2 in x.antecedent\n",
    "    recom = list(filter(ar, mineAssociationRules(history, support, conf)))\n",
    "    if len(recom): print(*recom)\n",
    "    else: print(\"No recommendation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario 2\n",
    "Des utilisateurs identifiés ont attribué un certain nombre d'étoiles (représentant leur appréciation) à des objets (identifiés par `P001`, `P002`, etc., ici) sur une plateforme de vente en ligne de type CDiscount. Ces appréciations sont contenues dans le fichier `dataQuestion2/etoiles.csv` qui peut être ouvert en utilisant la fonction `read_grades_from_csv()` du module `io_utils`.  \n",
    "Cette fonction renvoie trois conteneurs:\n",
    "\n",
    "- un dictionnaire du nombre d'étoiles attribuées, avec comme clés les paires (utilisateur, produit) et comme valeurs les nombres d'étoiles;\n",
    "- une liste de tous les utilisateurs identifiés;\n",
    "- une liste de tous les produits.\n",
    "\n",
    "Écrire le code permettant de prédire les nombres d'étoiles pour les évaluations manquantes avec une prédiction basée utilisateur et d'afficher ces appréciations avec, pour chacune, le nom de l'utilisateur et l'identifiant de l'objet correspondant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Daniels -> P005: 4\n",
      "   Holler -> P003: 1\n",
      "   Holler -> P005: 2\n",
      "   Holler -> P008: 2\n",
      "   Holler -> P013: 2\n",
      "   Litton -> P002: 4\n",
      "   Litton -> P008: 3\n",
      "   Litton -> P015: 3\n",
      "   Mooney -> P003: 2\n",
      "   Mooney -> P007: 3\n",
      "   Mooney -> P012: 2\n",
      "    Smith -> P006: 4\n",
      "Sternberg -> P006: 4\n",
      "Sternberg -> P007: 3\n",
      "Sternberg -> P015: 2\n",
      "  Whipple -> P004: 3\n",
      "  Whipple -> P009: 5\n",
      "  Whipple -> P011: 4\n",
      "  Whipple -> P012: 3\n"
     ]
    }
   ],
   "source": [
    "given, users, items = read_grades_from_csv(\"dataQuestion2/etoiles.csv\")\n",
    "empty = [(u,i) for u in users for i in items if (u,i) not in given.keys()]\n",
    "user_based = lambda x:(x, round(user_based_collaborative_filtering(given, x)))\n",
    "for (u,i),n in map(user_based, empty):\n",
    "    print(f'{u:>9} -> {i:>1}: {n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario 3\n",
    "\n",
    "On considère ici que l'entreprise a récolté des données supplémentaires sur son site de vente en ligne concernant ses produits. D'une part elle a pu dégager une liste de paires de produits souvent associés par les utilisateurs, soit parce qu'ils sont fréquemment achetés ensemble, soit parce qu'ils sont souvent consultés tous les deux lors d'une même session de navigation sur le site.  \n",
    "Cette liste de paires de produits associés est donnée dans le fichier `dataQuestion3/paires_produits.txt`.\n",
    "\n",
    "D'autre part, l'entreprise a récupéré pour chaque produit le nombre d'avis déposés par les utilisateurs du site depuis leur mise en vente sur le site (on ne connait pas la date de mise en ligne des produits).  \n",
    "Ces données sont enregistrées dans le fichier `dataQuestion3/produits_avis.txt` avec sur chaque ligne, l'identifiant du produit suivi du nombre d'avis concernant ce produit.  \n",
    "En outre, on dispose toujours des appréciations attribuées aux produits par des utilisateurs identifiés dans le fichier `dataQuestion3/etoiles.csv`.\n",
    "\n",
    "## Question 1\n",
    "Utilisez ces informations pour prédire la note qu'attribuerait l'utilisateur Smith au produit P006 pour une **prédiction basée items** et avec une mesure de similarité qui **n'utilise pas les notes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted note given by Smith for P006: 4\n"
     ]
    }
   ],
   "source": [
    "graph_1 = nx.readwrite.edgelist.read_edgelist(\"dataQuestion3/paires_produits.txt\", create_using=nx.Graph())\n",
    "given,_,_ = read_grades_from_csv(\"dataQuestion3/etoiles.csv\")\n",
    "print(f\"Predicted note given by Smith for P006: {item_based_collaborative_filtering(given, ('Smith', 'P006'), graph=graph_1) :.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Donnez des paires de produits non présentes dans le fichier `dataQuestion3/paires_produits.txt` qui pourraient probablement être associés (vous afficherez les 10 paires les plus probables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P006 -> P001 with score of 1.243\n",
      "P006 -> P004 with score of 1.243\n",
      "P006 -> P008 with score of 1.243\n",
      "P012 -> P003 with score of 1.243\n",
      "P012 -> P010 with score of 1.243\n",
      "P012 -> P015 with score of 1.243\n",
      "P011 -> P009 with score of 0.910\n",
      "P011 -> P007 with score of 0.910\n",
      "P011 -> P010 with score of 0.910\n",
      "P012 -> P014 with score of 0.910\n"
     ]
    }
   ],
   "source": [
    "for i1,i2,n in top_k_triplets(generic_adamic_adar(graph_1), 10):\n",
    "    print(f'{i1:>4} -> {i2:>4} with score of {n:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario 4\n",
    "On dispose cette fois-ci, en plus des appréciations (fichier `dataQuestion4/etoiles.csv`), d'une hiérarchie de catégories associée à chaque objet. Cette liste est disponible dans le fichier `dataQuestion4/categories_produits.txt`. Par exemple, la première ligne:  \n",
    "```sh\n",
    "P001 Livre,BD\n",
    "```\n",
    "indique que l'objet `P001` appartient à la catégorie Livre et plus précisément à la sous-catégorie BD. On souhaite pour cette question utiliser une similarité entre objets basée sur ces catégories et non passur les notes.\n",
    "\n",
    "La fonction `collaborative_filtering()` du module graphs a été modifiée pour pouvoir accepter comme paramètre supplémentaire une liste de catégories associées à des items. Lorsqu'il est utilisé, ce paramètre nommé `categories` doit être un dictionnaire dont les clés sont les identifiants des items, et les valeurs sont les listes de catégories associées. Lorsqu'on veut utiliser le paramètre `categories` il est obligatoire de préciser la fonction de similarité utilisée entre ces listes de catégories en passant sa référence en paramètre de `collaborative_filtering()` (paramètre `similarity_fun`).\n",
    "\n",
    "La similarité basée catégories entre deux objets sera de 0 s'ils n'appartiennent pas à la même catégorie (et donc pas non plus à la même sous-catégorie), de 0.5 s'ils appartiennent à la même catégorie mais pas à la même sous-catégorie et enfin de 1 s'ils appartiennent à la même catégorie et à la même sous-catégorie.\n",
    "## Question 1\n",
    "Construire une fonction qui prend en paramètre deux listes de catégorie+sous-catégorie, et renvoie la mesure de similarité définie ci-dessus. Vous testerez cette fonction avec différentes liste de catégorie+sous-catégorie de votre choix dans le programme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(*args):\n",
    "    sim = int(args[0] == args[1])\n",
    "    if not sim and args[0][0] == args[1][0]:\n",
    "        sim = .5\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Livre', 'BD'] and   ['Multimedia', 'Smartphone'] -> 0\n",
      "['Livre', 'BD'] and                ['Livre', 'BD'] -> 1\n",
      "['Livre', 'BD'] and   ['Livre', 'Manuel_scolaire'] -> 0.5\n"
     ]
    }
   ],
   "source": [
    "categories = read_txt_to_dic(\"dataQuestion4/categories_produits.txt\")\n",
    "cat_list = list(categories.values())\n",
    "for i in (3,4,5):\n",
    "    print(f\"{cat_list[0]} and {repr(cat_list[i]):>30} -> {similarity(cat_list[0], cat_list[i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Construire une fonction qui permet de calculer une liste de similarités entre paires d'items à partir de catégories associées à ces items. La fonction prend en premier paramètre un dictionnaire où les clés sont des identifiants d'items et les valeurs les listes de catégories/sous-catégories associées, et en second paramètre une liste de tuple d'identifiant d'items (`item1`, `item2`) entre lesquels on souhaite calculer la similarité définie ci-dessus.\n",
    "\n",
    "Le retour de la fonction doit être de même forme que celui des fonctions `nx.adamic_adar()` et `cosine_sim_all()` : une liste de triplets `(item1, item2, similarity)` où les deux premiers éléments sont les identifiants des items, et le troisième, la mesure de similarité calculée entre ces deux items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_sim_all(categories, pairs):\n",
    "    return [\n",
    "        (u,v,similarity(categories[u], categories[v]))\n",
    "        for u,v in pairs\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Construire la fonction `item_based_collaborative_filtering_with_categories()` qui permet d'appeler `collaborative_filtering()` du module `graphs` avec un dictionnaire de catégories associées à de sitems et la fonction de similarité de la question précédente, pour de la **recommandation basée items**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_based_collaborative_filtering_with_categories(scores, target, categories, n_neighbors=5, similarity_fun=cat_sim_all, graph=None):\n",
    "        i_scores = {(item, user): score for ((user, item), score) in scores.items()}\n",
    "        i_target = (target[1], target[0])\n",
    "        return collaborative_filtering(i_scores, i_target, n_neighbors, similarity_fun, graph, categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "Utiliser la fonction `item_based_collaborative_filtering_with_categories()` pour prédire la note qu'attribuerait l'utilisateur `Whipple` au produit `P009`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted note given by Whipple for P009: 5\n"
     ]
    }
   ],
   "source": [
    "given,_,_ = read_grades_from_csv(\"dataQuestion4/etoiles.csv\")\n",
    "print(f\"Predicted note given by Whipple for P009: {item_based_collaborative_filtering_with_categories(given, ('Whipple', 'P009'), categories) :.0f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
