{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = dict()\n",
    "for d in ('', '_basic', '_classic', '_classic_nos_nol'):\n",
    "    train = pd.read_pickle(f'../data/datasets/train{d}.pkl')\n",
    "    val = pd.read_pickle(f'../data/datasets/val{d}.pkl')\n",
    "    d = 'nopreproc' if d == '' else d[1:]\n",
    "    datasets[d] = (train, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"Logistic Regression\", \"SGD Classifier\", \"KNN\", \"Linear SVM\", \"RBF SVM\",\n",
    "    \"Decision Tree\", \"Random Forest\", \"AdaBoost\", \"Naive Bayes\",\n",
    "    \"QDA\"\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(alpha=.0001, max_iter=100),\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "lbencoder = LabelBinarizer()\n",
    "vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf = True, max_df = 0.5,\n",
    "    stop_words = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = list()\n",
    "i = 1\n",
    "for dataname, data in datasets.items():\n",
    "    y_train, x_train = data[0].label, data[0].tweet\n",
    "    y_val, x_val = data[1].label, data[1].tweet\n",
    "    \n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "    y_val = encoder.transform(y_val)\n",
    "    \n",
    "    x_train = vectorizer.fit_transform(x_train)\n",
    "    x_val = vectorizer.transform(x_val)\n",
    "    \n",
    "    for name, clf in zip(names, classifiers):\n",
    "        print(f'{i} of 40: {dataname} with {name}' , end = '\\r', flush = True)\n",
    "        try:\n",
    "            clf.fit(x_train, y_train)\n",
    "            y_pred = clf.predict(x_val)\n",
    "        except TypeError:\n",
    "            clf.fit(x_train.toarray(), y_train)\n",
    "            y_pred = clf.predict(x_val.toarray())\n",
    "        scores.append({\n",
    "            \"data\": dataname,\n",
    "            \"model\": name,\n",
    "            \"accuracy\": accuracy_score(y_val, y_pred),\n",
    "            \"f1_score\": f1_score(y_val, y_pred, average = \"macro\"),\n",
    "            \"auc\": roc_auc_score(\n",
    "                lbencoder.fit_transform(y_val),\n",
    "                lbencoder.fit_transform(y_pred),\n",
    "                average = \"macro\", multi_class = 'ovr')\n",
    "        })\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(scores).sort_values(by = ['f1_score', 'auc'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>classic</td>\n",
       "      <td>SGD Classifier</td>\n",
       "      <td>0.709375</td>\n",
       "      <td>0.608302</td>\n",
       "      <td>0.717033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nopreproc</td>\n",
       "      <td>SGD Classifier</td>\n",
       "      <td>0.671094</td>\n",
       "      <td>0.582889</td>\n",
       "      <td>0.697898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>classic_nos_nol</td>\n",
       "      <td>SGD Classifier</td>\n",
       "      <td>0.675781</td>\n",
       "      <td>0.573454</td>\n",
       "      <td>0.693037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>basic</td>\n",
       "      <td>SGD Classifier</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.560490</td>\n",
       "      <td>0.690356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>classic</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.698438</td>\n",
       "      <td>0.517371</td>\n",
       "      <td>0.662689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>classic_nos_nol</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.494052</td>\n",
       "      <td>0.646813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>basic</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.610938</td>\n",
       "      <td>0.487661</td>\n",
       "      <td>0.654789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nopreproc</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.610938</td>\n",
       "      <td>0.486920</td>\n",
       "      <td>0.659867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>classic</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.477684</td>\n",
       "      <td>0.646555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>classic_nos_nol</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.610156</td>\n",
       "      <td>0.475462</td>\n",
       "      <td>0.645948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nopreproc</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.468440</td>\n",
       "      <td>0.639735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>basic</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.666406</td>\n",
       "      <td>0.468225</td>\n",
       "      <td>0.639695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>classic</td>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.446476</td>\n",
       "      <td>0.616773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>basic</td>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.445601</td>\n",
       "      <td>0.615659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nopreproc</td>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>0.654687</td>\n",
       "      <td>0.444519</td>\n",
       "      <td>0.614833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>classic_nos_nol</td>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>0.646875</td>\n",
       "      <td>0.435084</td>\n",
       "      <td>0.608860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>classic_nos_nol</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.533594</td>\n",
       "      <td>0.434089</td>\n",
       "      <td>0.634649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nopreproc</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.532031</td>\n",
       "      <td>0.420511</td>\n",
       "      <td>0.625834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>basic</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.420011</td>\n",
       "      <td>0.625341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>classic</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.497656</td>\n",
       "      <td>0.408976</td>\n",
       "      <td>0.621264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>classic</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.528125</td>\n",
       "      <td>0.333282</td>\n",
       "      <td>0.555473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>basic</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.560156</td>\n",
       "      <td>0.295295</td>\n",
       "      <td>0.555655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nopreproc</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.535937</td>\n",
       "      <td>0.294494</td>\n",
       "      <td>0.547792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nopreproc</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.559375</td>\n",
       "      <td>0.294454</td>\n",
       "      <td>0.555126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>classic</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.577344</td>\n",
       "      <td>0.279866</td>\n",
       "      <td>0.556691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>basic</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.535937</td>\n",
       "      <td>0.273052</td>\n",
       "      <td>0.538933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>classic_nos_nol</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.570312</td>\n",
       "      <td>0.268869</td>\n",
       "      <td>0.548671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>classic_nos_nol</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.536719</td>\n",
       "      <td>0.266773</td>\n",
       "      <td>0.535763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nopreproc</td>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.528906</td>\n",
       "      <td>0.172969</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nopreproc</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.528906</td>\n",
       "      <td>0.172969</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>basic</td>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.528906</td>\n",
       "      <td>0.172969</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>basic</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.528906</td>\n",
       "      <td>0.172969</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>classic</td>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.528906</td>\n",
       "      <td>0.172969</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>classic</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.528906</td>\n",
       "      <td>0.172969</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>classic_nos_nol</td>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.528906</td>\n",
       "      <td>0.172969</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>classic_nos_nol</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.528906</td>\n",
       "      <td>0.172969</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>classic</td>\n",
       "      <td>QDA</td>\n",
       "      <td>0.096875</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>0.539142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>classic_nos_nol</td>\n",
       "      <td>QDA</td>\n",
       "      <td>0.088281</td>\n",
       "      <td>0.107923</td>\n",
       "      <td>0.519474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>basic</td>\n",
       "      <td>QDA</td>\n",
       "      <td>0.080469</td>\n",
       "      <td>0.101462</td>\n",
       "      <td>0.533355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nopreproc</td>\n",
       "      <td>QDA</td>\n",
       "      <td>0.064844</td>\n",
       "      <td>0.075994</td>\n",
       "      <td>0.512055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               data                model  accuracy  f1_score       auc\n",
       "21          classic       SGD Classifier  0.709375  0.608302  0.717033\n",
       "1         nopreproc       SGD Classifier  0.671094  0.582889  0.697898\n",
       "31  classic_nos_nol       SGD Classifier  0.675781  0.573454  0.693037\n",
       "11            basic       SGD Classifier  0.671875  0.560490  0.690356\n",
       "20          classic  Logistic Regression  0.698438  0.517371  0.662689\n",
       "30  classic_nos_nol  Logistic Regression  0.675000  0.494052  0.646813\n",
       "12            basic                  KNN  0.610938  0.487661  0.654789\n",
       "2         nopreproc                  KNN  0.610938  0.486920  0.659867\n",
       "22          classic                  KNN  0.609375  0.477684  0.646555\n",
       "32  classic_nos_nol                  KNN  0.610156  0.475462  0.645948\n",
       "0         nopreproc  Logistic Regression  0.664062  0.468440  0.639735\n",
       "10            basic  Logistic Regression  0.666406  0.468225  0.639695\n",
       "24          classic              RBF SVM  0.656250  0.446476  0.616773\n",
       "14            basic              RBF SVM  0.656250  0.445601  0.615659\n",
       "4         nopreproc              RBF SVM  0.654687  0.444519  0.614833\n",
       "34  classic_nos_nol              RBF SVM  0.646875  0.435084  0.608860\n",
       "38  classic_nos_nol          Naive Bayes  0.533594  0.434089  0.634649\n",
       "8         nopreproc          Naive Bayes  0.532031  0.420511  0.625834\n",
       "18            basic          Naive Bayes  0.531250  0.420011  0.625341\n",
       "28          classic          Naive Bayes  0.497656  0.408976  0.621264\n",
       "27          classic             AdaBoost  0.528125  0.333282  0.555473\n",
       "15            basic        Decision Tree  0.560156  0.295295  0.555655\n",
       "7         nopreproc             AdaBoost  0.535937  0.294494  0.547792\n",
       "5         nopreproc        Decision Tree  0.559375  0.294454  0.555126\n",
       "25          classic        Decision Tree  0.577344  0.279866  0.556691\n",
       "17            basic             AdaBoost  0.535937  0.273052  0.538933\n",
       "35  classic_nos_nol        Decision Tree  0.570312  0.268869  0.548671\n",
       "37  classic_nos_nol             AdaBoost  0.536719  0.266773  0.535763\n",
       "3         nopreproc           Linear SVM  0.528906  0.172969  0.500000\n",
       "6         nopreproc        Random Forest  0.528906  0.172969  0.500000\n",
       "13            basic           Linear SVM  0.528906  0.172969  0.500000\n",
       "16            basic        Random Forest  0.528906  0.172969  0.500000\n",
       "23          classic           Linear SVM  0.528906  0.172969  0.500000\n",
       "26          classic        Random Forest  0.528906  0.172969  0.500000\n",
       "33  classic_nos_nol           Linear SVM  0.528906  0.172969  0.500000\n",
       "36  classic_nos_nol        Random Forest  0.528906  0.172969  0.500000\n",
       "29          classic                  QDA  0.096875  0.114986  0.539142\n",
       "39  classic_nos_nol                  QDA  0.088281  0.107923  0.519474\n",
       "19            basic                  QDA  0.080469  0.101462  0.533355\n",
       "9         nopreproc                  QDA  0.064844  0.075994  0.512055"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.sort_values(by = ['f1_score', 'accuracy', 'auc'], ascending = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
