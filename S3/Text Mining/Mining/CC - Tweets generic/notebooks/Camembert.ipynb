{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Camembert",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJO3nR1UT8vj",
        "outputId": "8c3c4e63-bcca-4b51-f529-0238fb848af5"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSZShK44T9oM"
      },
      "source": [
        "import os\r\n",
        "os.chdir(\"/content/gdrive/My Drive/Studies/tweets/\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2raiuJ9DUc3i"
      },
      "source": [
        "pip install transformers sentencepiece imblearn --quiet"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc399LzqU0D0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be7ea2b9-b70d-4099-afac-f006cf58af2e"
      },
      "source": [
        "import gc\r\n",
        "from glob import glob\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import tensorflow as tf\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "from tensorflow.keras import layers, backend as K\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping, Callback\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\r\n",
        "from sklearn.metrics import (\r\n",
        "    f1_score, roc_auc_score, confusion_matrix,\r\n",
        "    accuracy_score, classification_report\r\n",
        ")\r\n",
        "\r\n",
        "from imblearn.keras import balanced_batch_generator\r\n",
        "from imblearn.over_sampling import RandomOverSampler\r\n",
        "\r\n",
        "import transformers as tr\r\n",
        "from transformers import TFAutoModel, AutoTokenizer\r\n",
        "from transformers.modeling_tf_utils import TFSequenceClassificationLoss"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICat1pIfVYxm",
        "outputId": "eb7cdb5c-18c1-4523-efcb-c1f0ccae2058"
      },
      "source": [
        "tf.get_logger().setLevel('ERROR')\r\n",
        "try:\r\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\r\n",
        "    print('Running on TPU ', tpu.master())\r\n",
        "except ValueError:\r\n",
        "    tpu = None\r\n",
        "\r\n",
        "if tpu:\r\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\r\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\r\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\r\n",
        "else:\r\n",
        "    strategy = tf.distribute.get_strategy()\r\n",
        "\r\n",
        "print(f\"{'='*80}\\nREPLICAS: {strategy.num_replicas_in_sync}\\n{'='*80}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running on TPU  grpc://10.17.49.242:8470\n",
            "================================================================================\n",
            "REPLICAS: 8\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz6OxDqhWnbn"
      },
      "source": [
        "class Camembert(tr.TFRobertaPreTrainedModel, TFSequenceClassificationLoss):\r\n",
        "    \"\"\"\r\n",
        "    Classic classifier w/ transformer layer: Camembert\r\n",
        "    Using CLS token representation\r\n",
        "    Output: array of (batch_size, num_labels)\r\n",
        "    \"\"\"\r\n",
        "    config_class = tr.CamembertConfig\r\n",
        "    _keys_to_ignore_on_load_missing = [r\"pooler\", r\"lm_head\"]\r\n",
        "    \r\n",
        "    def __init__(self, config, *inputs, **kwargs):\r\n",
        "        super().__init__(config, *inputs, **kwargs)\r\n",
        "        self.camembert = tr.TFRobertaMainLayer(\r\n",
        "            config,\r\n",
        "            name = \"ro_camembert\")\r\n",
        "        self.stride = layers.Lambda(lambda x: x[:, 0, :], name = \"stride\")\r\n",
        "        self.classifier = layers.Dense(\r\n",
        "            4,\r\n",
        "            activation = tf.keras.activations.softmax,\r\n",
        "            name = \"classifier\")\r\n",
        "    \r\n",
        "    def call(self, inputs = None, **kwargs):\r\n",
        "        outputs = self.camembert(inputs, **kwargs)\r\n",
        "        sequences = outputs[0]\r\n",
        "        cls_token = self.stride(sequences)\r\n",
        "        return self.classifier(cls_token)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmAEhaGjYslN"
      },
      "source": [
        "class Save(Callback):\r\n",
        "  def __init__(self, path = \"./\", monitor = 'loss'):\r\n",
        "    super(Save, self).__init__()\r\n",
        "    self.path = path\r\n",
        "    self.monitor = monitor\r\n",
        "\r\n",
        "  def on_epoch_end(self, epoch, logs = None):\r\n",
        "    path = f\"{self.path}{epoch}-{logs[self.monitor]}\"\r\n",
        "    self.model.save_pretrained(path)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPhb4U2Hb-el"
      },
      "source": [
        "# Modèle sans prétraitement\r\n",
        "Uniquement les URLs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FdDEIQOWSAd"
      },
      "source": [
        "train = pd.read_pickle('datasets/train_basic.pkl')\r\n",
        "val = pd.read_pickle('datasets/val_basic.pkl')\r\n",
        "test = pd.read_pickle('datasets/test_basic.pkl')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJutUpDyakFE",
        "outputId": "1fc61391-8a2e-4354-b727-02251390934d"
      },
      "source": [
        "AUTO = tf.data.experimental.AUTOTUNE\r\n",
        "BATCH_SIZE = 16*strategy.num_replicas_in_sync\r\n",
        "BATCH_D = BATCH_SIZE\r\n",
        "MAX_LEN = 26\r\n",
        "N_LABELS = 4\r\n",
        "BUFFER = 300000\r\n",
        "SEED = 42069\r\n",
        "MODEL = \"cam_base\"\r\n",
        "NTRAIN = train.shape[0]\r\n",
        "NVAL = val.shape[0]\r\n",
        "STEPS = int(np.ceil(NTRAIN/BATCH_D))\r\n",
        "VAL_STEPS = int(np.ceil(NVAL/BATCH_D))\r\n",
        "\r\n",
        "print(\"Total Steps:\", STEPS)\r\n",
        "print(\"Total Validation Steps:\", VAL_STEPS)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Steps: 40\n",
            "Total Validation Steps: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3hsfgaQjii-"
      },
      "source": [
        "tr.set_seed(SEED)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XCvRlkUZV5a",
        "outputId": "9ed13b1f-ffb6-4775-9aac-44082b1817a0"
      },
      "source": [
        "with strategy.scope():\r\n",
        "  model = Camembert.from_pretrained(f\"weights/{MODEL}\")\r\n",
        "  tokenizer = AutoTokenizer.from_pretrained(f\"weights/{MODEL}\")\r\n",
        "\r\n",
        "  save = Save(path = f\"weights/{MODEL}/epochs/\", monitor = \"val_loss\")\r\n",
        "  early = tf.keras.callbacks.EarlyStopping(\r\n",
        "      monitor = 'val_loss',\r\n",
        "      patience = 2,\r\n",
        "      restore_best_weights = True\r\n",
        "  )\r\n",
        "  callbacks = [save, early]\r\n",
        "  "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing Camembert.\n",
            "\n",
            "All the layers of Camembert were initialized from the model checkpoint at weights/cam_base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use Camembert for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVYqDHsOiC-Y"
      },
      "source": [
        "with strategy.scope():\r\n",
        "  model.layers[0].trainable = False\r\n",
        "  optimizer = tf.keras.optimizers.Adam(lr=1e-5)\r\n",
        "  model.compile(optimizer = optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5yLerz3engF"
      },
      "source": [
        "encoder = LabelEncoder()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF8qkefqeV6W"
      },
      "source": [
        "x_train = tokenizer.batch_encode_plus(\r\n",
        "  train.tweet.to_list(), truncation=True, \r\n",
        "  return_tensors='tf', max_length=MAX_LEN,\r\n",
        "  return_attention_mask = False,\r\n",
        "  padding = \"max_length\")['input_ids']\r\n",
        "\r\n",
        "x_val = tokenizer.batch_encode_plus(\r\n",
        "  val.tweet.to_list(), truncation=True, \r\n",
        "  return_tensors='tf', max_length=MAX_LEN,\r\n",
        "  return_attention_mask = False,\r\n",
        "  padding = \"max_length\")['input_ids']\r\n",
        "\r\n",
        "x_test = tokenizer.batch_encode_plus(\r\n",
        "  test.tweet.to_list(), truncation=True, \r\n",
        "  return_tensors='tf', max_length=MAX_LEN,\r\n",
        "  return_attention_mask = False,\r\n",
        "  padding = \"max_length\")['input_ids']\r\n",
        "\r\n",
        "y_train = encoder.fit_transform(train.label)\r\n",
        "y_val = encoder.transform(val.label)\r\n",
        "y_test = encoder.transform(test.label)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ66jH1EfGdb"
      },
      "source": [
        "train_dataset = (\r\n",
        "    tf.data.Dataset\r\n",
        "    .from_tensor_slices((x_train, y_train))\r\n",
        "    .repeat()\r\n",
        "    .shuffle(BUFFER)\r\n",
        "    .batch(BATCH_D)\r\n",
        "    .prefetch(AUTO)\r\n",
        ")\r\n",
        "\r\n",
        "val_dataset = (\r\n",
        "    tf.data.Dataset\r\n",
        "    .from_tensor_slices((x_val, y_val))\r\n",
        "    .batch(BATCH_D)\r\n",
        "    .prefetch(AUTO)\r\n",
        ")\r\n",
        "\r\n",
        "test_dataset = (\r\n",
        "    tf.data.Dataset\r\n",
        "    .from_tensor_slices(x_test)\r\n",
        "    .batch(BATCH_D)\r\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xn2jLqydoSEC"
      },
      "source": [
        "## Entraînement du modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4kjDjf5glDZ",
        "outputId": "b7829b45-67a6-4554-991a-3c0bd4d34dcc"
      },
      "source": [
        "epochs_done = 0\r\n",
        "history = model.fit(\r\n",
        "  train_dataset,\r\n",
        "  epochs = 200,\r\n",
        "  steps_per_epoch = STEPS,\r\n",
        "  callbacks = [early],\r\n",
        "  validation_data = val_dataset,\r\n",
        "  initial_epoch = epochs_done,\r\n",
        "  workers = 8,\r\n",
        "  use_multiprocessing = True\r\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "40/40 [==============================] - 28s 196ms/step - loss: 3.0774 - accuracy: 0.0130 - val_loss: 3.0072 - val_accuracy: 0.0117\n",
            "Epoch 2/200\n",
            "40/40 [==============================] - 2s 50ms/step - loss: 2.7675 - accuracy: 0.0156 - val_loss: 2.6517 - val_accuracy: 0.0117\n",
            "Epoch 3/200\n",
            "40/40 [==============================] - 2s 50ms/step - loss: 2.4744 - accuracy: 0.0273 - val_loss: 2.3334 - val_accuracy: 0.0117\n",
            "Epoch 4/200\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 2.2068 - accuracy: 0.0296 - val_loss: 2.0647 - val_accuracy: 0.0117\n",
            "Epoch 5/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 2.0042 - accuracy: 0.0518 - val_loss: 1.8430 - val_accuracy: 0.0117\n",
            "Epoch 6/200\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 1.8198 - accuracy: 0.1018 - val_loss: 1.6631 - val_accuracy: 0.0117\n",
            "Epoch 7/200\n",
            "40/40 [==============================] - 2s 63ms/step - loss: 1.7074 - accuracy: 0.1513 - val_loss: 1.5225 - val_accuracy: 0.0180\n",
            "Epoch 8/200\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 1.5752 - accuracy: 0.2055 - val_loss: 1.4139 - val_accuracy: 0.0969\n",
            "Epoch 9/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.4903 - accuracy: 0.2686 - val_loss: 1.3297 - val_accuracy: 0.3109\n",
            "Epoch 10/200\n",
            "40/40 [==============================] - 2s 50ms/step - loss: 1.4482 - accuracy: 0.2997 - val_loss: 1.2650 - val_accuracy: 0.4938\n",
            "Epoch 11/200\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 1.3682 - accuracy: 0.3488 - val_loss: 1.2156 - val_accuracy: 0.5211\n",
            "Epoch 12/200\n",
            "40/40 [==============================] - 2s 50ms/step - loss: 1.3432 - accuracy: 0.3741 - val_loss: 1.1776 - val_accuracy: 0.5289\n",
            "Epoch 13/200\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 1.2767 - accuracy: 0.4056 - val_loss: 1.1500 - val_accuracy: 0.5289\n",
            "Epoch 14/200\n",
            "40/40 [==============================] - 2s 50ms/step - loss: 1.2718 - accuracy: 0.4206 - val_loss: 1.1260 - val_accuracy: 0.5305\n",
            "Epoch 15/200\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 1.2597 - accuracy: 0.4240 - val_loss: 1.1072 - val_accuracy: 0.5320\n",
            "Epoch 16/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.2186 - accuracy: 0.4465 - val_loss: 1.0924 - val_accuracy: 0.5328\n",
            "Epoch 17/200\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 1.2306 - accuracy: 0.4387 - val_loss: 1.0803 - val_accuracy: 0.5320\n",
            "Epoch 18/200\n",
            "40/40 [==============================] - 3s 65ms/step - loss: 1.2004 - accuracy: 0.4632 - val_loss: 1.0716 - val_accuracy: 0.5320\n",
            "Epoch 19/200\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 1.1636 - accuracy: 0.4710 - val_loss: 1.0652 - val_accuracy: 0.5297\n",
            "Epoch 20/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.1881 - accuracy: 0.4687 - val_loss: 1.0575 - val_accuracy: 0.5305\n",
            "Epoch 21/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.1583 - accuracy: 0.4703 - val_loss: 1.0519 - val_accuracy: 0.5305\n",
            "Epoch 22/200\n",
            "40/40 [==============================] - 2s 54ms/step - loss: 1.1722 - accuracy: 0.4570 - val_loss: 1.0473 - val_accuracy: 0.5305\n",
            "Epoch 23/200\n",
            "40/40 [==============================] - 2s 53ms/step - loss: 1.1900 - accuracy: 0.4555 - val_loss: 1.0418 - val_accuracy: 0.5305\n",
            "Epoch 24/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.1326 - accuracy: 0.4790 - val_loss: 1.0391 - val_accuracy: 0.5297\n",
            "Epoch 25/200\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 1.1338 - accuracy: 0.4816 - val_loss: 1.0368 - val_accuracy: 0.5289\n",
            "Epoch 26/200\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 1.1357 - accuracy: 0.4817 - val_loss: 1.0349 - val_accuracy: 0.5289\n",
            "Epoch 27/200\n",
            "40/40 [==============================] - 2s 53ms/step - loss: 1.1560 - accuracy: 0.4695 - val_loss: 1.0314 - val_accuracy: 0.5297\n",
            "Epoch 28/200\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 1.1028 - accuracy: 0.4776 - val_loss: 1.0309 - val_accuracy: 0.5289\n",
            "Epoch 29/200\n",
            "40/40 [==============================] - 2s 53ms/step - loss: 1.1250 - accuracy: 0.4797 - val_loss: 1.0291 - val_accuracy: 0.5289\n",
            "Epoch 30/200\n",
            "40/40 [==============================] - 3s 65ms/step - loss: 1.1363 - accuracy: 0.4706 - val_loss: 1.0263 - val_accuracy: 0.5305\n",
            "Epoch 31/200\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 1.1074 - accuracy: 0.4840 - val_loss: 1.0240 - val_accuracy: 0.5305\n",
            "Epoch 32/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.1098 - accuracy: 0.4777 - val_loss: 1.0227 - val_accuracy: 0.5305\n",
            "Epoch 33/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.1135 - accuracy: 0.4813 - val_loss: 1.0220 - val_accuracy: 0.5289\n",
            "Epoch 34/200\n",
            "40/40 [==============================] - 2s 53ms/step - loss: 1.1443 - accuracy: 0.4719 - val_loss: 1.0205 - val_accuracy: 0.5297\n",
            "Epoch 35/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.1213 - accuracy: 0.4738 - val_loss: 1.0195 - val_accuracy: 0.5297\n",
            "Epoch 36/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.1182 - accuracy: 0.4789 - val_loss: 1.0194 - val_accuracy: 0.5305\n",
            "Epoch 37/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.1290 - accuracy: 0.4736 - val_loss: 1.0185 - val_accuracy: 0.5305\n",
            "Epoch 38/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.1168 - accuracy: 0.4684 - val_loss: 1.0180 - val_accuracy: 0.5297\n",
            "Epoch 39/200\n",
            "40/40 [==============================] - 2s 55ms/step - loss: 1.1178 - accuracy: 0.4652 - val_loss: 1.0174 - val_accuracy: 0.5305\n",
            "Epoch 40/200\n",
            "40/40 [==============================] - 2s 53ms/step - loss: 1.1135 - accuracy: 0.4746 - val_loss: 1.0160 - val_accuracy: 0.5305\n",
            "Epoch 41/200\n",
            "40/40 [==============================] - 3s 65ms/step - loss: 1.1032 - accuracy: 0.4729 - val_loss: 1.0167 - val_accuracy: 0.5297\n",
            "Epoch 42/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.0944 - accuracy: 0.4884 - val_loss: 1.0184 - val_accuracy: 0.5289\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYK365TCky7s"
      },
      "source": [
        "with strategy.scope():\r\n",
        "  model.layers[0].trainable = True\r\n",
        "  optimizer = tf.keras.optimizers.Adam(lr=1e-7)\r\n",
        "  model.compile(optimizer = optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0yzQP6dlNj5",
        "outputId": "d8909b54-dbed-49d8-faa9-a9a7cd66b86a"
      },
      "source": [
        "epochs_done = 42\r\n",
        "history = model.fit(\r\n",
        "  train_dataset,\r\n",
        "  epochs = 200,\r\n",
        "  steps_per_epoch = STEPS,\r\n",
        "  callbacks = [early],\r\n",
        "  validation_data = val_dataset,\r\n",
        "  initial_epoch = epochs_done,\r\n",
        "  workers = 8,\r\n",
        "  use_multiprocessing = True\r\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 43/200\n",
            "40/40 [==============================] - 73s 254ms/step - loss: 1.0975 - accuracy: 0.4689 - val_loss: 1.0151 - val_accuracy: 0.5297\n",
            "Epoch 44/200\n",
            "40/40 [==============================] - 4s 100ms/step - loss: 1.1267 - accuracy: 0.4699 - val_loss: 1.0102 - val_accuracy: 0.5312\n",
            "Epoch 45/200\n",
            "40/40 [==============================] - 4s 100ms/step - loss: 1.0906 - accuracy: 0.4769 - val_loss: 1.0142 - val_accuracy: 0.5305\n",
            "Epoch 46/200\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 1.0684 - accuracy: 0.5024 - val_loss: 1.0170 - val_accuracy: 0.5297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmhPsP6pqAxr"
      },
      "source": [
        "model.save_pretrained(f\"weights/{MODEL}/nopreproc\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRtgnphInxP7"
      },
      "source": [
        "## Evaluation du modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwmb8woxpUUh"
      },
      "source": [
        "train_dataset = (\r\n",
        "    tf.data.Dataset\r\n",
        "    .from_tensor_slices((\r\n",
        "        tf.concat([x_train, x_val], axis = 0),\r\n",
        "        np.concatenate([y_train, y_val])\r\n",
        "      ))\r\n",
        "    .repeat()\r\n",
        "    .shuffle(BUFFER)\r\n",
        "    .batch(BATCH_D)\r\n",
        "    .prefetch(AUTO)\r\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD9m2fcno0zN",
        "outputId": "9d085bb1-19aa-403a-8555-baead0ae3db0"
      },
      "source": [
        "with strategy.scope():\r\n",
        "  final_model_1 = Camembert.from_pretrained(f\"weights/{MODEL}\")\r\n",
        "  final_model_1.layers[0].trainable = False\r\n",
        "  optimizer = tf.keras.optimizers.Adam(lr=1e-5)\r\n",
        "  final_model_1.compile(optimizer = optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "epochs_done = 0\r\n",
        "history = final_model_1.fit(\r\n",
        "  train_dataset,\r\n",
        "  epochs = 42,\r\n",
        "  steps_per_epoch = STEPS,\r\n",
        "  initial_epoch = epochs_done,\r\n",
        "  workers = 8, verbose = 0,\r\n",
        "  use_multiprocessing = True\r\n",
        ")\r\n",
        "\r\n",
        "with strategy.scope():\r\n",
        "  final_model_1.layers[0].trainable = True\r\n",
        "  optimizer = tf.keras.optimizers.Adam(lr=1e-7)\r\n",
        "  final_model_1.compile(optimizer = optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "epochs_done = 42\r\n",
        "history = final_model_1.fit(\r\n",
        "  train_dataset,\r\n",
        "  epochs = epochs_done + 4,\r\n",
        "  steps_per_epoch = STEPS,\r\n",
        "  initial_epoch = epochs_done,\r\n",
        "  workers = 8, verbose = 0,\r\n",
        "  use_multiprocessing = True\r\n",
        ")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing Camembert.\n",
            "\n",
            "All the layers of Camembert were initialized from the model checkpoint at weights/cam_base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use Camembert for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCoiybRJo3rL"
      },
      "source": [
        "pred_1 = final_model_1.predict(x_test)\r\n",
        "y_1 = encoder.inverse_transform(np.argmax(pred_1, axis = 1))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVI2Z5kOteSS"
      },
      "source": [
        "binarizer = LabelBinarizer()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "fQj20u8lsPEw",
        "outputId": "f8a152d4-d575-4629-92c5-f37721a56022"
      },
      "source": [
        "print(classification_report(test.label, y_1))\r\n",
        "\r\n",
        "print(\"F1-score: {}\\nAUC: {}\\nAccuracy: {}\".format(\r\n",
        "    f1_score(test.label, y_1, average = \"macro\"),\r\n",
        "    roc_auc_score(binarizer.fit_transform(y_test), pred_1, average = \"macro\", multi_class = \"ovr\"),\r\n",
        "    accuracy_score(test.label, y_1)\r\n",
        "))\r\n",
        "\r\n",
        "sns.heatmap(\r\n",
        "    confusion_matrix(test.label, y_1, normalize='true'),\r\n",
        "    annot = True\r\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     EMOTION       0.00      0.00      0.00       337\n",
            " INFORMATION       0.45      0.98      0.62      1473\n",
            "     OPINION       0.29      0.03      0.05       950\n",
            "   SENTIMENT       0.00      0.00      0.00       523\n",
            "\n",
            "    accuracy                           0.45      3283\n",
            "   macro avg       0.19      0.25      0.17      3283\n",
            "weighted avg       0.29      0.45      0.29      3283\n",
            "\n",
            "F1-score: 0.16691491641663095\n",
            "AUC: 0.556569793051824\n",
            "Accuracy: 0.4468473956746878\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f25b8a55eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzpFOTHJRSpd"
      },
      "source": [
        "# Modèle sans prétraitement avec sur-échantillonnage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hOA4J_DkaAv"
      },
      "source": [
        "## Entraînement\r\n",
        "\r\n",
        "Sur-échantillonnage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqttCZQrZHQI",
        "outputId": "6add14ca-b345-4ea1-bcf0-e14932a44cab"
      },
      "source": [
        "ros = RandomOverSampler(\r\n",
        "    sampling_strategy={\r\n",
        "        0: 1746,\r\n",
        "        1: 2707,\r\n",
        "        2: 1746,\r\n",
        "        3: 1746\r\n",
        "    }\r\n",
        ")\r\n",
        "x_ros, y_ros = ros.fit_resample(x_train, y_train)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mU7pKp2Rw2_",
        "outputId": "d2c21557-bcde-4135-da9a-06afb521ef83"
      },
      "source": [
        "with strategy.scope():\r\n",
        "  model_2 = Camembert.from_pretrained(f\"weights/{MODEL}\")\r\n",
        "  model_2.layers[0].trainable = False\r\n",
        "  optimizer = tf.keras.optimizers.Adam(lr=1e-5)\r\n",
        "  model_2.compile(optimizer = optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "  train_ros_dataset = (\r\n",
        "      tf.data.Dataset\r\n",
        "      .from_tensor_slices((x_ros, y_ros))\r\n",
        "      .repeat()\r\n",
        "      .shuffle(BUFFER)\r\n",
        "      .batch(BATCH_D)\r\n",
        "      .prefetch(AUTO)\r\n",
        "  )\r\n",
        "\r\n",
        "epochs_done = 0\r\n",
        "history = model_2.fit(\r\n",
        "  train_ros_dataset,\r\n",
        "  epochs = 200,\r\n",
        "  steps_per_epoch = int(np.ceil(x_ros.shape[0]/BATCH_D)),\r\n",
        "  callbacks = [early],\r\n",
        "  validation_data = val_dataset,\r\n",
        "  initial_epoch = epochs_done,\r\n",
        "  workers = 8,\r\n",
        "  use_multiprocessing = True\r\n",
        ")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing Camembert.\n",
            "\n",
            "All the layers of Camembert were initialized from the model checkpoint at weights/cam_base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use Camembert for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "63/63 [==============================] - 27s 132ms/step - loss: 2.3550 - accuracy: 0.2172 - val_loss: 2.8032 - val_accuracy: 0.0117\n",
            "Epoch 2/200\n",
            "63/63 [==============================] - 3s 40ms/step - loss: 2.0519 - accuracy: 0.2019 - val_loss: 2.3283 - val_accuracy: 0.0117\n",
            "Epoch 3/200\n",
            "63/63 [==============================] - 3s 41ms/step - loss: 1.8314 - accuracy: 0.2062 - val_loss: 1.9829 - val_accuracy: 0.0117\n",
            "Epoch 4/200\n",
            "63/63 [==============================] - 3s 41ms/step - loss: 1.6656 - accuracy: 0.2262 - val_loss: 1.7412 - val_accuracy: 0.0117\n",
            "Epoch 5/200\n",
            "63/63 [==============================] - 3s 41ms/step - loss: 1.6098 - accuracy: 0.2204 - val_loss: 1.5724 - val_accuracy: 0.0125\n",
            "Epoch 6/200\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 1.5373 - accuracy: 0.2537 - val_loss: 1.4679 - val_accuracy: 0.0672\n",
            "Epoch 7/200\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 1.5309 - accuracy: 0.2450 - val_loss: 1.3896 - val_accuracy: 0.2609\n",
            "Epoch 8/200\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 1.5227 - accuracy: 0.2496 - val_loss: 1.3453 - val_accuracy: 0.4344\n",
            "Epoch 9/200\n",
            "63/63 [==============================] - 3s 41ms/step - loss: 1.5085 - accuracy: 0.2664 - val_loss: 1.3240 - val_accuracy: 0.5031\n",
            "Epoch 10/200\n",
            "63/63 [==============================] - 3s 41ms/step - loss: 1.5000 - accuracy: 0.2801 - val_loss: 1.3069 - val_accuracy: 0.5219\n",
            "Epoch 11/200\n",
            "63/63 [==============================] - 3s 41ms/step - loss: 1.5044 - accuracy: 0.2762 - val_loss: 1.2946 - val_accuracy: 0.5281\n",
            "Epoch 12/200\n",
            "63/63 [==============================] - 3s 41ms/step - loss: 1.4968 - accuracy: 0.2700 - val_loss: 1.2859 - val_accuracy: 0.5281\n",
            "Epoch 13/200\n",
            "63/63 [==============================] - 3s 41ms/step - loss: 1.4892 - accuracy: 0.2894 - val_loss: 1.2852 - val_accuracy: 0.5281\n",
            "Epoch 14/200\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 1.4932 - accuracy: 0.2873 - val_loss: 1.2840 - val_accuracy: 0.5273\n",
            "Epoch 15/200\n",
            "63/63 [==============================] - 3s 41ms/step - loss: 1.5064 - accuracy: 0.2787 - val_loss: 1.2831 - val_accuracy: 0.5281\n",
            "Epoch 16/200\n",
            "63/63 [==============================] - 3s 41ms/step - loss: 1.5009 - accuracy: 0.2749 - val_loss: 1.2910 - val_accuracy: 0.5266\n",
            "Epoch 17/200\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 1.5043 - accuracy: 0.2735 - val_loss: 1.2760 - val_accuracy: 0.5281\n",
            "Epoch 18/200\n",
            "63/63 [==============================] - 3s 41ms/step - loss: 1.4931 - accuracy: 0.2830 - val_loss: 1.2761 - val_accuracy: 0.5273\n",
            "Epoch 19/200\n",
            "63/63 [==============================] - 3s 41ms/step - loss: 1.4869 - accuracy: 0.2889 - val_loss: 1.2774 - val_accuracy: 0.5266\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95ikNSG2iGFm",
        "outputId": "ece13830-ee23-46f6-9c57-252b491a3b75"
      },
      "source": [
        "with strategy.scope():\r\n",
        "  model_2.layers[0].trainable = True\r\n",
        "  optimizer = tf.keras.optimizers.Adam(lr=1e-7)\r\n",
        "  model.compile(optimizer = optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "epochs_done = 16\r\n",
        "history = model_2.fit(\r\n",
        "  train_ros_dataset,\r\n",
        "  epochs = 200,\r\n",
        "  steps_per_epoch = int(np.ceil(x_ros.shape[0]/BATCH_D)),\r\n",
        "  callbacks = [early],\r\n",
        "  validation_data = val_dataset,\r\n",
        "  initial_epoch = epochs_done,\r\n",
        "  workers = 8,\r\n",
        "  use_multiprocessing = True\r\n",
        ")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 17/200\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 1.5060 - accuracy: 0.2724 - val_loss: 1.2761 - val_accuracy: 0.5281\n",
            "Epoch 18/200\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 1.4926 - accuracy: 0.2819 - val_loss: 1.2721 - val_accuracy: 0.5273\n",
            "Epoch 19/200\n",
            "63/63 [==============================] - 3s 41ms/step - loss: 1.4851 - accuracy: 0.2862 - val_loss: 1.2875 - val_accuracy: 0.5242\n",
            "Epoch 20/200\n",
            "63/63 [==============================] - 3s 41ms/step - loss: 1.4966 - accuracy: 0.2790 - val_loss: 1.2819 - val_accuracy: 0.5234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A82n99JVkohs"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2lebxWwlPnl",
        "outputId": "b1ac27c6-e839-45ed-8737-f60eccc5d253"
      },
      "source": [
        "counts = np.sort(np.unique(np.concatenate([y_train, y_val]), return_counts = True)[1])\r\n",
        "ros = RandomOverSampler(sampling_strategy={\r\n",
        "    0: counts[-2],\r\n",
        "    1: counts[-1],\r\n",
        "    2: counts[-2],\r\n",
        "    3: counts[-2]\r\n",
        "})\r\n",
        "\r\n",
        "x_ros, y_ros = ros.fit_resample(\r\n",
        "    tf.concat([x_train, x_val], axis = 0),\r\n",
        "    np.concatenate([y_train, y_val])\r\n",
        ")\r\n",
        "\r\n",
        "train_ros_dataset = (\r\n",
        "    tf.data.Dataset\r\n",
        "    .from_tensor_slices((x_ros, y_ros))\r\n",
        "    .repeat()\r\n",
        "    .shuffle(BUFFER)\r\n",
        "    .batch(BATCH_D)\r\n",
        "    .prefetch(AUTO)\r\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zjz9IrPjm32x",
        "outputId": "417a03f5-09b8-40cd-8eaa-18ab044c2b7d"
      },
      "source": [
        "with strategy.scope():\r\n",
        "  final_model_2 = Camembert.from_pretrained(f\"weights/{MODEL}\")\r\n",
        "  final_model_2.layers[0].trainable = False\r\n",
        "  optimizer = tf.keras.optimizers.Adam(lr=1e-5)\r\n",
        "  final_model_2.compile(optimizer = optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "epochs_done = 0\r\n",
        "history = final_model_2.fit(\r\n",
        "  train_ros_dataset,\r\n",
        "  epochs = 14,\r\n",
        "  steps_per_epoch = int(np.ceil(x_ros.shape[0]/BATCH_D)),\r\n",
        "  initial_epoch = epochs_done,\r\n",
        "  workers = 8, verbose = 0,\r\n",
        "  use_multiprocessing = True\r\n",
        ")\r\n",
        "\r\n",
        "with strategy.scope():\r\n",
        "  final_model_2.layers[0].trainable = True\r\n",
        "  optimizer = tf.keras.optimizers.Adam(lr=1e-7)\r\n",
        "  final_model_2.compile(optimizer = optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "epochs_done = 14\r\n",
        "history = final_model_2.fit(\r\n",
        "  train_ros_dataset,\r\n",
        "  epochs = epochs_done + 2,\r\n",
        "  steps_per_epoch = int(np.ceil(x_ros.shape[0]/BATCH_D)),\r\n",
        "  initial_epoch = epochs_done,\r\n",
        "  workers = 8, verbose = 0,\r\n",
        "  use_multiprocessing = True\r\n",
        ")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing Camembert.\n",
            "\n",
            "All the layers of Camembert were initialized from the model checkpoint at weights/cam_base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use Camembert for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "7o9nc79ao2wX",
        "outputId": "b8cde6e4-24f1-4ba2-d8f5-88c26591ac16"
      },
      "source": [
        "pred_2 = final_model_2.predict(x_test)\r\n",
        "y_2 = encoder.inverse_transform(np.argmax(pred_2, axis = 1))\r\n",
        "\r\n",
        "print(classification_report(test.label, y_2))\r\n",
        "\r\n",
        "print(\"F1-score: {}\\nAUC: {}\\nAccuracy: {}\".format(\r\n",
        "    f1_score(test.label, y_2, average = \"macro\"),\r\n",
        "    roc_auc_score(binarizer.fit_transform(y_test), pred_2, average = \"macro\", multi_class = \"ovr\"),\r\n",
        "    accuracy_score(test.label, y_2)\r\n",
        "))\r\n",
        "\r\n",
        "sns.heatmap(\r\n",
        "    confusion_matrix(test.label, y_2, normalize='true'),\r\n",
        "    annot = True\r\n",
        ")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     EMOTION       0.14      0.02      0.03       337\n",
            " INFORMATION       0.45      0.98      0.62      1473\n",
            "     OPINION       0.24      0.00      0.01       950\n",
            "   SENTIMENT       0.19      0.01      0.02       523\n",
            "\n",
            "    accuracy                           0.44      3283\n",
            "   macro avg       0.25      0.25      0.17      3283\n",
            "weighted avg       0.32      0.44      0.29      3283\n",
            "\n",
            "F1-score: 0.16961180650050448\n",
            "AUC: 0.5760699559595379\n",
            "Accuracy: 0.44319220225403594\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f259549cc88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDrLVED1vfWC"
      },
      "source": [
        "# Modèle avec prétraitement mais sans Lem-Stem\r\n",
        "Données classic_nos_nol"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEEEnsjqrmbh"
      },
      "source": [
        "train = pd.read_pickle('datasets/train_classic_nos_nol.pkl')\r\n",
        "val = pd.read_pickle('datasets/val_classic_nos_nol.pkl')\r\n",
        "test = pd.read_pickle('datasets/test_classic_nos_nol.pkl')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrNRFvp8rmbi",
        "outputId": "9ef55448-0285-4e1f-ba37-9457cb1a5974"
      },
      "source": [
        "AUTO = tf.data.experimental.AUTOTUNE\r\n",
        "BATCH_SIZE = 16*strategy.num_replicas_in_sync\r\n",
        "BATCH_D = BATCH_SIZE\r\n",
        "MAX_LEN = 26\r\n",
        "N_LABELS = 4\r\n",
        "BUFFER = 300000\r\n",
        "SEED = 42069\r\n",
        "MODEL = \"cam_base\"\r\n",
        "NTRAIN = train.shape[0]\r\n",
        "NVAL = val.shape[0]\r\n",
        "STEPS = int(np.ceil(NTRAIN/BATCH_D))\r\n",
        "VAL_STEPS = int(np.ceil(NVAL/BATCH_D))\r\n",
        "\r\n",
        "print(\"Total Steps:\", STEPS)\r\n",
        "print(\"Total Validation Steps:\", VAL_STEPS)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Steps: 40\n",
            "Total Validation Steps: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3C1tniFyrmbj",
        "outputId": "a76ea34d-bdec-474c-ff31-2fa3d8d71a02"
      },
      "source": [
        "with strategy.scope():\r\n",
        "  model_3 = Camembert.from_pretrained(f\"weights/{MODEL}\")\r\n",
        "  tokenizer = AutoTokenizer.from_pretrained(f\"weights/{MODEL}\")\r\n",
        "\r\n",
        "  save = Save(path = f\"weights/{MODEL}/epochs/\", monitor = \"val_loss\")\r\n",
        "  early = tf.keras.callbacks.EarlyStopping(\r\n",
        "      monitor = 'val_loss',\r\n",
        "      patience = 2,\r\n",
        "      restore_best_weights = True\r\n",
        "  )\r\n",
        "  callbacks = [save, early]\r\n",
        "  "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing Camembert.\n",
            "\n",
            "All the layers of Camembert were initialized from the model checkpoint at weights/cam_base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use Camembert for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-riFGHprmbk"
      },
      "source": [
        "with strategy.scope():\r\n",
        "  model_3.layers[0].trainable = False\r\n",
        "  optimizer = tf.keras.optimizers.Adam(lr=1e-5)\r\n",
        "  model_3.compile(optimizer = optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkr0d59nrmbk"
      },
      "source": [
        "x_train = tokenizer.batch_encode_plus(\r\n",
        "  train.tweet.to_list(), truncation=True, \r\n",
        "  return_tensors='tf', max_length=MAX_LEN,\r\n",
        "  return_attention_mask = False,\r\n",
        "  padding = \"max_length\")['input_ids']\r\n",
        "\r\n",
        "x_val = tokenizer.batch_encode_plus(\r\n",
        "  val.tweet.to_list(), truncation=True, \r\n",
        "  return_tensors='tf', max_length=MAX_LEN,\r\n",
        "  return_attention_mask = False,\r\n",
        "  padding = \"max_length\")['input_ids']\r\n",
        "\r\n",
        "x_test = tokenizer.batch_encode_plus(\r\n",
        "  test.tweet.to_list(), truncation=True, \r\n",
        "  return_tensors='tf', max_length=MAX_LEN,\r\n",
        "  return_attention_mask = False,\r\n",
        "  padding = \"max_length\")['input_ids']\r\n",
        "\r\n",
        "y_train = encoder.fit_transform(train.label)\r\n",
        "y_val = encoder.transform(val.label)\r\n",
        "y_test = encoder.transform(test.label)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGqYDInmrmbk"
      },
      "source": [
        "train_dataset = (\r\n",
        "    tf.data.Dataset\r\n",
        "    .from_tensor_slices((x_train, y_train))\r\n",
        "    .repeat()\r\n",
        "    .shuffle(BUFFER)\r\n",
        "    .batch(BATCH_D)\r\n",
        "    .prefetch(AUTO)\r\n",
        ")\r\n",
        "\r\n",
        "val_dataset = (\r\n",
        "    tf.data.Dataset\r\n",
        "    .from_tensor_slices((x_val, y_val))\r\n",
        "    .batch(BATCH_D)\r\n",
        "    .prefetch(AUTO)\r\n",
        ")\r\n",
        "\r\n",
        "test_dataset = (\r\n",
        "    tf.data.Dataset\r\n",
        "    .from_tensor_slices(x_test)\r\n",
        "    .batch(BATCH_D)\r\n",
        ")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHZgM8KWrmbl"
      },
      "source": [
        "## Entraînement du modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cejIwyirmbl",
        "outputId": "c1d59d41-e2f5-4de9-a4fe-7730e9722a18"
      },
      "source": [
        "epochs_done = 0\r\n",
        "history = model_3.fit(\r\n",
        "  train_dataset,\r\n",
        "  epochs = 200,\r\n",
        "  steps_per_epoch = STEPS,\r\n",
        "  callbacks = [early],\r\n",
        "  validation_data = val_dataset,\r\n",
        "  initial_epoch = epochs_done,\r\n",
        "  workers = 8,\r\n",
        "  use_multiprocessing = True\r\n",
        ")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "40/40 [==============================] - 25s 196ms/step - loss: 3.1365 - accuracy: 0.0121 - val_loss: 3.0849 - val_accuracy: 0.0117\n",
            "Epoch 2/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 2.8501 - accuracy: 0.0132 - val_loss: 2.7224 - val_accuracy: 0.0117\n",
            "Epoch 3/200\n",
            "40/40 [==============================] - 2s 54ms/step - loss: 2.4882 - accuracy: 0.0212 - val_loss: 2.3979 - val_accuracy: 0.0117\n",
            "Epoch 4/200\n",
            "40/40 [==============================] - 2s 53ms/step - loss: 2.2791 - accuracy: 0.0295 - val_loss: 2.1221 - val_accuracy: 0.0117\n",
            "Epoch 5/200\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 2.0670 - accuracy: 0.0557 - val_loss: 1.8888 - val_accuracy: 0.0117\n",
            "Epoch 6/200\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 1.8647 - accuracy: 0.0895 - val_loss: 1.6993 - val_accuracy: 0.0117\n",
            "Epoch 7/200\n",
            "40/40 [==============================] - 2s 53ms/step - loss: 1.7000 - accuracy: 0.1464 - val_loss: 1.5528 - val_accuracy: 0.0133\n",
            "Epoch 8/200\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 1.6138 - accuracy: 0.1908 - val_loss: 1.4379 - val_accuracy: 0.0359\n",
            "Epoch 9/200\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 1.5121 - accuracy: 0.2582 - val_loss: 1.3482 - val_accuracy: 0.2539\n",
            "Epoch 10/200\n",
            "40/40 [==============================] - 3s 88ms/step - loss: 1.4247 - accuracy: 0.3129 - val_loss: 1.2787 - val_accuracy: 0.4883\n",
            "Epoch 11/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.3517 - accuracy: 0.3490 - val_loss: 1.2266 - val_accuracy: 0.5063\n",
            "Epoch 12/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.3251 - accuracy: 0.3743 - val_loss: 1.1864 - val_accuracy: 0.5266\n",
            "Epoch 13/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.3019 - accuracy: 0.4051 - val_loss: 1.1560 - val_accuracy: 0.5312\n",
            "Epoch 14/200\n",
            "40/40 [==============================] - 2s 53ms/step - loss: 1.2566 - accuracy: 0.4299 - val_loss: 1.1310 - val_accuracy: 0.5289\n",
            "Epoch 15/200\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 1.2333 - accuracy: 0.4509 - val_loss: 1.1117 - val_accuracy: 0.5289\n",
            "Epoch 16/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.2190 - accuracy: 0.4508 - val_loss: 1.0966 - val_accuracy: 0.5289\n",
            "Epoch 17/200\n",
            "40/40 [==============================] - 2s 54ms/step - loss: 1.1915 - accuracy: 0.4727 - val_loss: 1.0845 - val_accuracy: 0.5281\n",
            "Epoch 18/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.2227 - accuracy: 0.4398 - val_loss: 1.0739 - val_accuracy: 0.5289\n",
            "Epoch 19/200\n",
            "40/40 [==============================] - 2s 53ms/step - loss: 1.1747 - accuracy: 0.4688 - val_loss: 1.0656 - val_accuracy: 0.5281\n",
            "Epoch 20/200\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 1.1599 - accuracy: 0.4653 - val_loss: 1.0591 - val_accuracy: 0.5289\n",
            "Epoch 21/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.1814 - accuracy: 0.4604 - val_loss: 1.0531 - val_accuracy: 0.5281\n",
            "Epoch 22/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.1422 - accuracy: 0.4800 - val_loss: 1.0492 - val_accuracy: 0.5281\n",
            "Epoch 23/200\n",
            "40/40 [==============================] - 2s 53ms/step - loss: 1.1535 - accuracy: 0.4788 - val_loss: 1.0443 - val_accuracy: 0.5281\n",
            "Epoch 24/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.1380 - accuracy: 0.4784 - val_loss: 1.0408 - val_accuracy: 0.5281\n",
            "Epoch 25/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.1319 - accuracy: 0.4730 - val_loss: 1.0387 - val_accuracy: 0.5281\n",
            "Epoch 26/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.1316 - accuracy: 0.4720 - val_loss: 1.0359 - val_accuracy: 0.5281\n",
            "Epoch 27/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.1127 - accuracy: 0.4832 - val_loss: 1.0340 - val_accuracy: 0.5281\n",
            "Epoch 28/200\n",
            "40/40 [==============================] - 2s 54ms/step - loss: 1.1464 - accuracy: 0.4636 - val_loss: 1.0314 - val_accuracy: 0.5281\n",
            "Epoch 29/200\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 1.1289 - accuracy: 0.4787 - val_loss: 1.0292 - val_accuracy: 0.5281\n",
            "Epoch 30/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.1545 - accuracy: 0.4698 - val_loss: 1.0271 - val_accuracy: 0.5281\n",
            "Epoch 31/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.1387 - accuracy: 0.4760 - val_loss: 1.0268 - val_accuracy: 0.5289\n",
            "Epoch 32/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.1093 - accuracy: 0.4866 - val_loss: 1.0259 - val_accuracy: 0.5281\n",
            "Epoch 33/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.1052 - accuracy: 0.4756 - val_loss: 1.0261 - val_accuracy: 0.5281\n",
            "Epoch 34/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.1610 - accuracy: 0.4489 - val_loss: 1.0236 - val_accuracy: 0.5289\n",
            "Epoch 35/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.1295 - accuracy: 0.4542 - val_loss: 1.0230 - val_accuracy: 0.5289\n",
            "Epoch 36/200\n",
            "40/40 [==============================] - 2s 53ms/step - loss: 1.1114 - accuracy: 0.4696 - val_loss: 1.0216 - val_accuracy: 0.5281\n",
            "Epoch 37/200\n",
            "40/40 [==============================] - 2s 53ms/step - loss: 1.1145 - accuracy: 0.4704 - val_loss: 1.0208 - val_accuracy: 0.5289\n",
            "Epoch 38/200\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 1.1011 - accuracy: 0.4732 - val_loss: 1.0212 - val_accuracy: 0.5281\n",
            "Epoch 39/200\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 1.1283 - accuracy: 0.4635 - val_loss: 1.0218 - val_accuracy: 0.5281\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ercU9Kprmbl"
      },
      "source": [
        "with strategy.scope():\r\n",
        "  model_3.layers[0].trainable = True\r\n",
        "  optimizer = tf.keras.optimizers.Adam(lr=1e-7)\r\n",
        "  model_3.compile(optimizer = optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvgyLxlVrmbm",
        "outputId": "a06839f8-7491-4594-c8e9-f90b4fa647f9"
      },
      "source": [
        "epochs_done = 40\r\n",
        "history = model_3.fit(\r\n",
        "  train_dataset,\r\n",
        "  epochs = 200,\r\n",
        "  steps_per_epoch = STEPS,\r\n",
        "  callbacks = [early],\r\n",
        "  validation_data = val_dataset,\r\n",
        "  initial_epoch = epochs_done,\r\n",
        "  workers = 8,\r\n",
        "  use_multiprocessing = True\r\n",
        ")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 41/200\n",
            "40/40 [==============================] - 77s 242ms/step - loss: 1.1093 - accuracy: 0.4798 - val_loss: 1.0229 - val_accuracy: 0.5273\n",
            "Epoch 42/200\n",
            "40/40 [==============================] - 4s 100ms/step - loss: 1.0965 - accuracy: 0.4831 - val_loss: 1.0205 - val_accuracy: 0.5266\n",
            "Epoch 43/200\n",
            "40/40 [==============================] - 4s 100ms/step - loss: 1.1030 - accuracy: 0.4745 - val_loss: 1.0169 - val_accuracy: 0.5273\n",
            "Epoch 44/200\n",
            "40/40 [==============================] - 4s 102ms/step - loss: 1.1059 - accuracy: 0.4699 - val_loss: 1.0168 - val_accuracy: 0.5281\n",
            "Epoch 45/200\n",
            "40/40 [==============================] - 4s 101ms/step - loss: 1.1202 - accuracy: 0.4640 - val_loss: 1.0296 - val_accuracy: 0.5289\n",
            "Epoch 46/200\n",
            "40/40 [==============================] - 4s 100ms/step - loss: 1.0938 - accuracy: 0.4913 - val_loss: 1.0202 - val_accuracy: 0.5273\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTPCc-urrmbm"
      },
      "source": [
        "model_3.save_pretrained(f\"weights/{MODEL}/nos_nol\")"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmBFxukfrmbm"
      },
      "source": [
        "## Evaluation du modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI3AYZKYrmbm"
      },
      "source": [
        "train_dataset = (\r\n",
        "    tf.data.Dataset\r\n",
        "    .from_tensor_slices((\r\n",
        "        tf.concat([x_train, x_val], axis = 0),\r\n",
        "        np.concatenate([y_train, y_val])\r\n",
        "      ))\r\n",
        "    .repeat()\r\n",
        "    .shuffle(BUFFER)\r\n",
        "    .batch(BATCH_D)\r\n",
        "    .prefetch(AUTO)\r\n",
        ")"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVwY-yR9rmbm",
        "outputId": "0e8759c3-dd64-4346-a192-6a81f2829c58"
      },
      "source": [
        "with strategy.scope():\r\n",
        "  final_model_3 = Camembert.from_pretrained(f\"weights/{MODEL}\")\r\n",
        "  final_model_3.layers[0].trainable = False\r\n",
        "  optimizer = tf.keras.optimizers.Adam(lr=1e-5)\r\n",
        "  final_model_3.compile(optimizer = optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "epochs_done = 0\r\n",
        "history = final_model_1.fit(\r\n",
        "  train_dataset,\r\n",
        "  epochs = 38,\r\n",
        "  steps_per_epoch = STEPS + 10,\r\n",
        "  initial_epoch = epochs_done,\r\n",
        "  workers = 8, verbose = 0,\r\n",
        "  use_multiprocessing = True\r\n",
        ")\r\n",
        "\r\n",
        "with strategy.scope():\r\n",
        "  final_model_3.layers[0].trainable = True\r\n",
        "  optimizer = tf.keras.optimizers.Adam(lr=1e-7)\r\n",
        "  final_model_3.compile(optimizer = optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "epochs_done = 38\r\n",
        "history = final_model_3.fit(\r\n",
        "  train_dataset,\r\n",
        "  epochs = epochs_done + 2,\r\n",
        "  steps_per_epoch = STEPS + 10,\r\n",
        "  initial_epoch = epochs_done,\r\n",
        "  workers = 8, verbose = 0,\r\n",
        "  use_multiprocessing = True\r\n",
        ")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing Camembert.\n",
            "\n",
            "All the layers of Camembert were initialized from the model checkpoint at weights/cam_base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use Camembert for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY8pCNkMrmbn"
      },
      "source": [
        "pred_3 = final_model_3.predict(x_test)\r\n",
        "y_3 = encoder.inverse_transform(np.argmax(pred_3, axis = 1))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "MR7Q7AKZrmbo",
        "outputId": "1a86378d-e8d3-46c9-a891-f87ff426d027"
      },
      "source": [
        "print(classification_report(test.label, y_3))\r\n",
        "\r\n",
        "print(\"F1-score: {}\\nAUC: {}\\nAccuracy: {}\".format(\r\n",
        "    f1_score(test.label, y_3, average = \"macro\"),\r\n",
        "    roc_auc_score(binarizer.fit_transform(y_test), pred_3, average = \"macro\", multi_class = \"ovr\"),\r\n",
        "    accuracy_score(test.label, y_3)\r\n",
        "))\r\n",
        "\r\n",
        "sns.heatmap(\r\n",
        "    confusion_matrix(test.label, y_3, normalize='true'),\r\n",
        "    annot = True\r\n",
        ")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     EMOTION       0.00      0.00      0.00       337\n",
            " INFORMATION       0.45      1.00      0.62      1473\n",
            "     OPINION       0.33      0.00      0.00       950\n",
            "   SENTIMENT       0.00      0.00      0.00       523\n",
            "\n",
            "    accuracy                           0.45      3283\n",
            "   macro avg       0.20      0.25      0.16      3283\n",
            "weighted avg       0.30      0.45      0.28      3283\n",
            "\n",
            "F1-score: 0.1554794243829876\n",
            "AUC: 0.5327091492978477\n",
            "Accuracy: 0.4489795918367347\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f258af9a208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imuGPUnormbo"
      },
      "source": [
        "# Modèle sans Stem-Lem avec sur-échantillonnage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZn87_Nirmbp"
      },
      "source": [
        "## Entraînement\r\n",
        "\r\n",
        "Sur-échantillonnage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1ukBXEPrmbp",
        "outputId": "e8993961-de79-4182-fa3e-1a6b23d727a7"
      },
      "source": [
        "ros = RandomOverSampler(\r\n",
        "    sampling_strategy={\r\n",
        "        0: 1746,\r\n",
        "        1: 2707,\r\n",
        "        2: 1746,\r\n",
        "        3: 1746\r\n",
        "    }\r\n",
        ")\r\n",
        "x_ros, y_ros = ros.fit_resample(x_train, y_train)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rc5O5B9brmbp",
        "outputId": "46253b84-c512-4730-8fc5-c184853cd060"
      },
      "source": [
        "with strategy.scope():\r\n",
        "  model_4 = Camembert.from_pretrained(f\"weights/{MODEL}\")\r\n",
        "  model_4.layers[0].trainable = False\r\n",
        "  optimizer = tf.keras.optimizers.Adam(lr=1e-5)\r\n",
        "  model_4.compile(optimizer = optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "  train_ros_dataset = (\r\n",
        "      tf.data.Dataset\r\n",
        "      .from_tensor_slices((x_ros, y_ros))\r\n",
        "      .repeat()\r\n",
        "      .shuffle(BUFFER)\r\n",
        "      .batch(BATCH_D)\r\n",
        "      .prefetch(AUTO)\r\n",
        "  )\r\n",
        "\r\n",
        "epochs_done = 0\r\n",
        "history = model_4.fit(\r\n",
        "  train_ros_dataset,\r\n",
        "  epochs = 200,\r\n",
        "  steps_per_epoch = int(np.ceil(x_ros.shape[0]/BATCH_D)),\r\n",
        "  callbacks = [early],\r\n",
        "  validation_data = val_dataset,\r\n",
        "  initial_epoch = epochs_done,\r\n",
        "  workers = 8,\r\n",
        "  use_multiprocessing = True\r\n",
        ")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing Camembert.\n",
            "\n",
            "All the layers of Camembert were initialized from the model checkpoint at weights/cam_base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use Camembert for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "63/63 [==============================] - 26s 132ms/step - loss: 2.4046 - accuracy: 0.2219 - val_loss: 2.8758 - val_accuracy: 0.0117\n",
            "Epoch 2/200\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 2.0928 - accuracy: 0.2163 - val_loss: 2.3917 - val_accuracy: 0.0117\n",
            "Epoch 3/200\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 1.8293 - accuracy: 0.2261 - val_loss: 2.0349 - val_accuracy: 0.0117\n",
            "Epoch 4/200\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 1.7163 - accuracy: 0.2121 - val_loss: 1.7747 - val_accuracy: 0.0117\n",
            "Epoch 5/200\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 1.5968 - accuracy: 0.2357 - val_loss: 1.5943 - val_accuracy: 0.0125\n",
            "Epoch 6/200\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 1.5567 - accuracy: 0.2327 - val_loss: 1.4787 - val_accuracy: 0.0266\n",
            "Epoch 7/200\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 1.5251 - accuracy: 0.2506 - val_loss: 1.4126 - val_accuracy: 0.1969\n",
            "Epoch 8/200\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 1.5102 - accuracy: 0.2616 - val_loss: 1.3696 - val_accuracy: 0.4352\n",
            "Epoch 9/200\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 1.4964 - accuracy: 0.2685 - val_loss: 1.3296 - val_accuracy: 0.5125\n",
            "Epoch 10/200\n",
            "63/63 [==============================] - 3s 41ms/step - loss: 1.5031 - accuracy: 0.2670 - val_loss: 1.3158 - val_accuracy: 0.5211\n",
            "Epoch 11/200\n",
            "63/63 [==============================] - 3s 41ms/step - loss: 1.5071 - accuracy: 0.2638 - val_loss: 1.3040 - val_accuracy: 0.5258\n",
            "Epoch 12/200\n",
            "63/63 [==============================] - 3s 41ms/step - loss: 1.4988 - accuracy: 0.2734 - val_loss: 1.2914 - val_accuracy: 0.5273\n",
            "Epoch 13/200\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 1.5067 - accuracy: 0.2613 - val_loss: 1.2864 - val_accuracy: 0.5273\n",
            "Epoch 14/200\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 1.4895 - accuracy: 0.2835 - val_loss: 1.2830 - val_accuracy: 0.5273\n",
            "Epoch 15/200\n",
            "63/63 [==============================] - 3s 41ms/step - loss: 1.4954 - accuracy: 0.2812 - val_loss: 1.2842 - val_accuracy: 0.5273\n",
            "Epoch 16/200\n",
            "63/63 [==============================] - 3s 41ms/step - loss: 1.4887 - accuracy: 0.2827 - val_loss: 1.2883 - val_accuracy: 0.5273\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF3sXtufrmbq",
        "outputId": "06b279b2-2e0a-4b08-dd29-520acdfdefc7"
      },
      "source": [
        "with strategy.scope():\r\n",
        "  model_4.layers[0].trainable = True\r\n",
        "  optimizer = tf.keras.optimizers.Adam(lr=1e-7)\r\n",
        "  model.compile(optimizer = optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "epochs_done = 20\r\n",
        "history = model_4.fit(\r\n",
        "  train_ros_dataset,\r\n",
        "  epochs = 200,\r\n",
        "  steps_per_epoch = int(np.ceil(x_ros.shape[0]/BATCH_D)),\r\n",
        "  callbacks = [early],\r\n",
        "  validation_data = val_dataset,\r\n",
        "  initial_epoch = epochs_done,\r\n",
        "  workers = 8,\r\n",
        "  use_multiprocessing = True\r\n",
        ")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 21/200\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 1.5049 - accuracy: 0.2728 - val_loss: 1.2827 - val_accuracy: 0.5273\n",
            "Epoch 22/200\n",
            "63/63 [==============================] - 3s 44ms/step - loss: 1.4901 - accuracy: 0.2805 - val_loss: 1.2773 - val_accuracy: 0.5273\n",
            "Epoch 23/200\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 1.4852 - accuracy: 0.2879 - val_loss: 1.2680 - val_accuracy: 0.5273\n",
            "Epoch 24/200\n",
            "63/63 [==============================] - 3s 43ms/step - loss: 1.4937 - accuracy: 0.2780 - val_loss: 1.2711 - val_accuracy: 0.5273\n",
            "Epoch 25/200\n",
            "63/63 [==============================] - 3s 45ms/step - loss: 1.4969 - accuracy: 0.2755 - val_loss: 1.2646 - val_accuracy: 0.5273\n",
            "Epoch 26/200\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 1.5050 - accuracy: 0.2769 - val_loss: 1.2746 - val_accuracy: 0.5273\n",
            "Epoch 27/200\n",
            "63/63 [==============================] - 3s 42ms/step - loss: 1.4873 - accuracy: 0.2878 - val_loss: 1.2759 - val_accuracy: 0.5273\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtqSEO-Vrmbq"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivQtR-SErmbq",
        "outputId": "9a255f7d-c265-437a-883c-4fd78ef5cf33"
      },
      "source": [
        "counts = np.sort(np.unique(np.concatenate([y_train, y_val]), return_counts = True)[1])\r\n",
        "ros = RandomOverSampler(sampling_strategy={\r\n",
        "    0: counts[-2],\r\n",
        "    1: counts[-1],\r\n",
        "    2: counts[-2],\r\n",
        "    3: counts[-2]\r\n",
        "})\r\n",
        "\r\n",
        "x_ros, y_ros = ros.fit_resample(\r\n",
        "    tf.concat([x_train, x_val], axis = 0),\r\n",
        "    np.concatenate([y_train, y_val])\r\n",
        ")\r\n",
        "\r\n",
        "train_ros_dataset = (\r\n",
        "    tf.data.Dataset\r\n",
        "    .from_tensor_slices((x_ros, y_ros))\r\n",
        "    .repeat()\r\n",
        "    .shuffle(BUFFER)\r\n",
        "    .batch(BATCH_D)\r\n",
        "    .prefetch(AUTO)\r\n",
        ")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeHcxiKU7RMr",
        "outputId": "def15f21-39ea-4e63-b99a-18cdc97b1fb4"
      },
      "source": [
        "del final_model_4\r\n",
        "del final_model_1\r\n",
        "del final_model_2\r\n",
        "del final_model_3\r\n",
        "del model\r\n",
        "del model_2\r\n",
        "del model_3\r\n",
        "del model_4\r\n",
        "gc.collect()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2394152"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYMx5BjCrmbq",
        "outputId": "5b5e8e0b-8eb5-49a0-c99b-e71015304017"
      },
      "source": [
        "with strategy.scope():\r\n",
        "  final_model_4 = Camembert.from_pretrained(f\"weights/{MODEL}\")\r\n",
        "  final_model_4.layers[0].trainable = False\r\n",
        "  optimizer = tf.keras.optimizers.Adam(lr=1e-5)\r\n",
        "  final_model_4.compile(optimizer = optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "epochs_done = 0\r\n",
        "history = final_model_4.fit(\r\n",
        "  train_ros_dataset,\r\n",
        "  epochs = 18,\r\n",
        "  steps_per_epoch = int(np.ceil(x_ros.shape[0]/BATCH_D)),\r\n",
        "  initial_epoch = epochs_done,\r\n",
        "  workers = 8, verbose = 0,\r\n",
        "  use_multiprocessing = True\r\n",
        ")\r\n",
        "\r\n",
        "with strategy.scope():\r\n",
        "  final_model_4.layers[0].trainable = True\r\n",
        "  optimizer = tf.keras.optimizers.Adam(lr=1e-7)\r\n",
        "  final_model_4.compile(optimizer = optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "epochs_done = 18\r\n",
        "history = final_model_4.fit(\r\n",
        "  train_ros_dataset,\r\n",
        "  epochs = epochs_done + 1,\r\n",
        "  steps_per_epoch = int(np.ceil(x_ros.shape[0]/BATCH_D)),\r\n",
        "  initial_epoch = epochs_done,\r\n",
        "  workers = 8, verbose = 0,\r\n",
        "  use_multiprocessing = True\r\n",
        ")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing Camembert.\n",
            "\n",
            "All the layers of Camembert were initialized from the model checkpoint at weights/cam_base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use Camembert for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "rc88cUsarmbr",
        "outputId": "ff0434da-0bba-443a-d1fb-9dc76cfcf403"
      },
      "source": [
        "pred_4 = final_model_4.predict(x_test)\r\n",
        "y_4 = encoder.inverse_transform(np.argmax(pred_4, axis = 1))\r\n",
        "\r\n",
        "print(classification_report(test.label, y_4))\r\n",
        "\r\n",
        "print(\"F1-score: {}\\nAUC: {}\\nAccuracy: {}\".format(\r\n",
        "    f1_score(test.label, y_4, average = \"macro\"),\r\n",
        "    roc_auc_score(binarizer.fit_transform(y_test), pred_4, average = \"macro\", multi_class = \"ovr\"),\r\n",
        "    accuracy_score(test.label, y_4)\r\n",
        "))\r\n",
        "\r\n",
        "sns.heatmap(\r\n",
        "    confusion_matrix(test.label, y_4, normalize='true'),\r\n",
        "    annot = True\r\n",
        ")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     EMOTION       0.00      0.00      0.00       337\n",
            " INFORMATION       0.45      1.00      0.62      1473\n",
            "     OPINION       0.00      0.00      0.00       950\n",
            "   SENTIMENT       0.00      0.00      0.00       523\n",
            "\n",
            "    accuracy                           0.45      3283\n",
            "   macro avg       0.11      0.25      0.15      3283\n",
            "weighted avg       0.20      0.45      0.28      3283\n",
            "\n",
            "F1-score: 0.15468156895824547\n",
            "AUC: 0.53759796720932\n",
            "Accuracy: 0.4468473956746878\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2598829470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}