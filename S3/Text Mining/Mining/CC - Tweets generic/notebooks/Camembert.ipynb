{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Camembert",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJO3nR1UT8vj",
        "outputId": "73c79084-c837-493f-9796-3207f7dc1b26"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSZShK44T9oM"
      },
      "source": [
        "import os\r\n",
        "os.chdir(\"/content/gdrive/My Drive/Studies/tweets/\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2raiuJ9DUc3i"
      },
      "source": [
        "pip install transformers sentencepiece --quiet"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc399LzqU0D0"
      },
      "source": [
        "import gc\r\n",
        "from glob import glob\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from tensorflow.keras import layers, backend as K\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping, Callback\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\r\n",
        "from sklearn.metrics import (\r\n",
        "    f1_score, roc_auc_score,\r\n",
        "    accuracy_score, classification_report\r\n",
        ")\r\n",
        "\r\n",
        "import transformers as tr\r\n",
        "from transformers import TFAutoModel, AutoTokenizer\r\n",
        "from transformers.modeling_tf_utils import TFSequenceClassificationLoss"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICat1pIfVYxm",
        "outputId": "08a6676d-6f23-4870-c76d-daf10b43fedf"
      },
      "source": [
        "tf.get_logger().setLevel('ERROR')\r\n",
        "try:\r\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\r\n",
        "    print('Running on TPU ', tpu.master())\r\n",
        "except ValueError:\r\n",
        "    tpu = None\r\n",
        "\r\n",
        "if tpu:\r\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\r\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\r\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\r\n",
        "else:\r\n",
        "    strategy = tf.distribute.get_strategy()\r\n",
        "\r\n",
        "print(f\"{'='*80}\\nREPLICAS: {strategy.num_replicas_in_sync}\\n{'='*80}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running on TPU  grpc://10.73.166.42:8470\n",
            "================================================================================\n",
            "REPLICAS: 8\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz6OxDqhWnbn"
      },
      "source": [
        "class Camembert(tr.TFRobertaPreTrainedModel, TFSequenceClassificationLoss):\r\n",
        "    \"\"\"\r\n",
        "    Classic classifier w/ transformer layer: Camembert\r\n",
        "    Using CLS token representation\r\n",
        "    Output: array of (batch_size, num_labels)\r\n",
        "    \"\"\"\r\n",
        "    config_class = tr.CamembertConfig\r\n",
        "    _keys_to_ignore_on_load_missing = [r\"pooler\", r\"lm_head\"]\r\n",
        "    \r\n",
        "    def __init__(self, config, *inputs, **kwargs):\r\n",
        "        super().__init__(config, *inputs, **kwargs)\r\n",
        "        self.camembert = tr.TFRobertaMainLayer(\r\n",
        "            config,\r\n",
        "            name = \"ro_camembert\")\r\n",
        "        self.stride = layers.Lambda(lambda x: x[:, 0, :], name = \"stride\")\r\n",
        "        self.classifier = layers.Dense(\r\n",
        "            4,\r\n",
        "            activation = tf.keras.activations.softmax,\r\n",
        "            name = \"classifier\")\r\n",
        "    \r\n",
        "    def call(self, inputs = None, **kwargs):\r\n",
        "        outputs = self.camembert(inputs, **kwargs)\r\n",
        "        sequences = outputs[0]\r\n",
        "        cls_token = self.stride(sequences)\r\n",
        "        return self.classifier(cls_token)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmAEhaGjYslN"
      },
      "source": [
        "class Save(Callback):\r\n",
        "  def __init__(self, path = \"./\", monitor = 'loss'):\r\n",
        "    super(Save, self).__init__()\r\n",
        "    self.path = path\r\n",
        "    self.monitor = monitor\r\n",
        "\r\n",
        "  def on_epoch_end(self, epoch, logs = None):\r\n",
        "    path = f\"{self.path}{epoch}-{logs[self.monitor]}\"\r\n",
        "    self.model.save_pretrained(path)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPhb4U2Hb-el"
      },
      "source": [
        "# Modèle sans prétraitement\r\n",
        "Uniquement les URLs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FdDEIQOWSAd"
      },
      "source": [
        "train = pd.read_pickle('datasets/train_basic.pkl')\r\n",
        "val = pd.read_pickle('datasets/val_basic.pkl')\r\n",
        "test = pd.read_pickle('datasets/test_basic.pkl')"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJutUpDyakFE",
        "outputId": "169b2886-aff3-44f3-b5cd-7269a5f5bb99"
      },
      "source": [
        "AUTO = tf.data.experimental.AUTOTUNE\r\n",
        "BATCH_SIZE = 16*strategy.num_replicas_in_sync\r\n",
        "BATCH_D = BATCH_SIZE\r\n",
        "MAX_LEN = 26\r\n",
        "N_LABELS = 4\r\n",
        "BUFFER = 300000\r\n",
        "SEED = 42069\r\n",
        "MODEL = \"cam_base\"\r\n",
        "NTRAIN = train.shape[0]\r\n",
        "NVAL = val.shape[0]\r\n",
        "STEPS = int(np.ceil(NTRAIN/BATCH_D))\r\n",
        "VAL_STEPS = int(np.ceil(NVAL/BATCH_D))\r\n",
        "\r\n",
        "print(\"Total Steps:\", STEPS)\r\n",
        "print(\"Total Validation Steps:\", VAL_STEPS)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Steps: 40\n",
            "Total Validation Steps: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3hsfgaQjii-"
      },
      "source": [
        "tr.set_seed(SEED)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XCvRlkUZV5a",
        "outputId": "9a78409c-5d4d-4436-a558-b9eb8a058b74"
      },
      "source": [
        "with strategy.scope():\r\n",
        "  model = Camembert.from_pretrained(f\"weights/{MODEL}\")\r\n",
        "  tokenizer = AutoTokenizer.from_pretrained(f\"weights/{MODEL}\")\r\n",
        "\r\n",
        "  save = Save(path = f\"weights/{MODEL}/epochs/\", monitor = \"val_loss\")\r\n",
        "  early = tf.keras.callbacks.EarlyStopping(\r\n",
        "      monitor = 'val_loss',\r\n",
        "      patience = 2,\r\n",
        "      restore_best_weights = True\r\n",
        "  )\r\n",
        "  callbacks = [save, early]\r\n",
        "  "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing Camembert.\n",
            "\n",
            "All the layers of Camembert were initialized from the model checkpoint at weights/cam_base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use Camembert for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVYqDHsOiC-Y"
      },
      "source": [
        "with strategy.scope():\r\n",
        "  model.layers[0].trainable = False\r\n",
        "  optimizer = tf.keras.optimizers.Adam(lr=1e-5)\r\n",
        "  model.compile(optimizer = optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5yLerz3engF"
      },
      "source": [
        "encoder = LabelEncoder()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF8qkefqeV6W"
      },
      "source": [
        "x_train = tokenizer.batch_encode_plus(\r\n",
        "  train.tweet.to_list(), truncation=True, \r\n",
        "  return_tensors='tf', max_length=MAX_LEN,\r\n",
        "  return_attention_mask = False,\r\n",
        "  padding = \"max_length\")['input_ids']\r\n",
        "\r\n",
        "x_val = tokenizer.batch_encode_plus(\r\n",
        "  val.tweet.to_list(), truncation=True, \r\n",
        "  return_tensors='tf', max_length=MAX_LEN,\r\n",
        "  return_attention_mask = False,\r\n",
        "  padding = \"max_length\")['input_ids']\r\n",
        "\r\n",
        "x_test = tokenizer.batch_encode_plus(\r\n",
        "  test.tweet.to_list(), truncation=True, \r\n",
        "  return_tensors='tf', max_length=MAX_LEN,\r\n",
        "  return_attention_mask = False,\r\n",
        "  padding = \"max_length\")['input_ids']\r\n",
        "\r\n",
        "y_train = encoder.fit_transform(train.label)\r\n",
        "y_val = encoder.transform(val.label)\r\n",
        "y_test = encoder.transform(test.label)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ66jH1EfGdb"
      },
      "source": [
        "train_dataset = (\r\n",
        "    tf.data.Dataset\r\n",
        "    .from_tensor_slices((x_train, y_train))\r\n",
        "    .repeat()\r\n",
        "    .shuffle(BUFFER)\r\n",
        "    .batch(BATCH_D)\r\n",
        "    .prefetch(AUTO)\r\n",
        ")\r\n",
        "\r\n",
        "val_dataset = (\r\n",
        "    tf.data.Dataset\r\n",
        "    .from_tensor_slices((x_val, y_val))\r\n",
        "    .batch(BATCH_D)\r\n",
        "    .prefetch(AUTO)\r\n",
        ")\r\n",
        "\r\n",
        "test_dataset = (\r\n",
        "    tf.data.Dataset\r\n",
        "    .from_tensor_slices(x_test)\r\n",
        "    .batch(BATCH_D)\r\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xn2jLqydoSEC"
      },
      "source": [
        "## Entraînement du modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4kjDjf5glDZ",
        "outputId": "8d15cf6b-d9c9-4f12-a258-08e90c5981c2"
      },
      "source": [
        "epochs_done = 0\r\n",
        "history = model.fit(\r\n",
        "  train_dataset,\r\n",
        "  epochs = 200,\r\n",
        "  steps_per_epoch = STEPS,\r\n",
        "  callbacks = [early],\r\n",
        "  validation_data = val_dataset,\r\n",
        "  initial_epoch = epochs_done,\r\n",
        "  workers = 8,\r\n",
        "  use_multiprocessing = True\r\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "40/40 [==============================] - 27s 198ms/step - loss: 3.0535 - accuracy: 0.0142 - val_loss: 3.0060 - val_accuracy: 0.0117\n",
            "Epoch 2/200\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 2.7615 - accuracy: 0.0182 - val_loss: 2.6513 - val_accuracy: 0.0117\n",
            "Epoch 3/200\n",
            "40/40 [==============================] - 2s 48ms/step - loss: 2.4501 - accuracy: 0.0231 - val_loss: 2.3339 - val_accuracy: 0.0117\n",
            "Epoch 4/200\n",
            "40/40 [==============================] - 2s 48ms/step - loss: 2.2099 - accuracy: 0.0325 - val_loss: 2.0657 - val_accuracy: 0.0117\n",
            "Epoch 5/200\n",
            "40/40 [==============================] - 2s 49ms/step - loss: 2.0070 - accuracy: 0.0556 - val_loss: 1.8430 - val_accuracy: 0.0117\n",
            "Epoch 6/200\n",
            "40/40 [==============================] - 2s 48ms/step - loss: 1.8359 - accuracy: 0.0991 - val_loss: 1.6609 - val_accuracy: 0.0117\n",
            "Epoch 7/200\n",
            "40/40 [==============================] - 2s 48ms/step - loss: 1.6798 - accuracy: 0.1701 - val_loss: 1.5232 - val_accuracy: 0.0172\n",
            "Epoch 8/200\n",
            "40/40 [==============================] - 2s 48ms/step - loss: 1.5761 - accuracy: 0.2149 - val_loss: 1.4142 - val_accuracy: 0.0977\n",
            "Epoch 9/200\n",
            "40/40 [==============================] - 2s 60ms/step - loss: 1.4875 - accuracy: 0.2794 - val_loss: 1.3290 - val_accuracy: 0.3148\n",
            "Epoch 10/200\n",
            "40/40 [==============================] - 2s 48ms/step - loss: 1.4320 - accuracy: 0.3155 - val_loss: 1.2651 - val_accuracy: 0.4969\n",
            "Epoch 11/200\n",
            "40/40 [==============================] - 2s 48ms/step - loss: 1.3663 - accuracy: 0.3473 - val_loss: 1.2143 - val_accuracy: 0.5266\n",
            "Epoch 12/200\n",
            "40/40 [==============================] - 2s 48ms/step - loss: 1.3274 - accuracy: 0.3930 - val_loss: 1.1772 - val_accuracy: 0.5266\n",
            "Epoch 13/200\n",
            "40/40 [==============================] - 2s 48ms/step - loss: 1.2868 - accuracy: 0.4055 - val_loss: 1.1496 - val_accuracy: 0.5312\n",
            "Epoch 14/200\n",
            "40/40 [==============================] - 2s 49ms/step - loss: 1.2630 - accuracy: 0.4242 - val_loss: 1.1259 - val_accuracy: 0.5312\n",
            "Epoch 15/200\n",
            "40/40 [==============================] - 2s 48ms/step - loss: 1.2687 - accuracy: 0.4341 - val_loss: 1.1069 - val_accuracy: 0.5328\n",
            "Epoch 16/200\n",
            "40/40 [==============================] - 2s 48ms/step - loss: 1.2319 - accuracy: 0.4356 - val_loss: 1.0925 - val_accuracy: 0.5320\n",
            "Epoch 17/200\n",
            "40/40 [==============================] - 2s 48ms/step - loss: 1.2301 - accuracy: 0.4480 - val_loss: 1.0803 - val_accuracy: 0.5312\n",
            "Epoch 18/200\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 1.2030 - accuracy: 0.4556 - val_loss: 1.0714 - val_accuracy: 0.5312\n",
            "Epoch 19/200\n",
            "40/40 [==============================] - 2s 59ms/step - loss: 1.1640 - accuracy: 0.4699 - val_loss: 1.0646 - val_accuracy: 0.5297\n",
            "Epoch 20/200\n",
            "40/40 [==============================] - 2s 48ms/step - loss: 1.1693 - accuracy: 0.4780 - val_loss: 1.0571 - val_accuracy: 0.5305\n",
            "Epoch 21/200\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 1.1608 - accuracy: 0.4687 - val_loss: 1.0513 - val_accuracy: 0.5305\n",
            "Epoch 22/200\n",
            "40/40 [==============================] - 2s 48ms/step - loss: 1.1494 - accuracy: 0.4714 - val_loss: 1.0469 - val_accuracy: 0.5305\n",
            "Epoch 23/200\n",
            "40/40 [==============================] - 2s 48ms/step - loss: 1.1859 - accuracy: 0.4429 - val_loss: 1.0416 - val_accuracy: 0.5305\n",
            "Epoch 24/200\n",
            "40/40 [==============================] - 2s 49ms/step - loss: 1.1398 - accuracy: 0.4845 - val_loss: 1.0390 - val_accuracy: 0.5297\n",
            "Epoch 25/200\n",
            "40/40 [==============================] - 2s 48ms/step - loss: 1.1280 - accuracy: 0.4815 - val_loss: 1.0366 - val_accuracy: 0.5289\n",
            "Epoch 26/200\n",
            "40/40 [==============================] - 2s 49ms/step - loss: 1.1429 - accuracy: 0.4759 - val_loss: 1.0349 - val_accuracy: 0.5289\n",
            "Epoch 27/200\n",
            "40/40 [==============================] - 2s 48ms/step - loss: 1.1527 - accuracy: 0.4683 - val_loss: 1.0313 - val_accuracy: 0.5305\n",
            "Epoch 28/200\n",
            "40/40 [==============================] - 2s 49ms/step - loss: 1.0944 - accuracy: 0.4939 - val_loss: 1.0304 - val_accuracy: 0.5289\n",
            "Epoch 29/200\n",
            "40/40 [==============================] - 2s 49ms/step - loss: 1.1233 - accuracy: 0.4834 - val_loss: 1.0294 - val_accuracy: 0.5289\n",
            "Epoch 30/200\n",
            "40/40 [==============================] - 2s 62ms/step - loss: 1.1227 - accuracy: 0.4676 - val_loss: 1.0263 - val_accuracy: 0.5305\n",
            "Epoch 31/200\n",
            "40/40 [==============================] - 2s 48ms/step - loss: 1.1218 - accuracy: 0.4747 - val_loss: 1.0238 - val_accuracy: 0.5305\n",
            "Epoch 32/200\n",
            "40/40 [==============================] - 2s 49ms/step - loss: 1.1218 - accuracy: 0.4748 - val_loss: 1.0231 - val_accuracy: 0.5305\n",
            "Epoch 33/200\n",
            "40/40 [==============================] - 2s 48ms/step - loss: 1.1134 - accuracy: 0.4844 - val_loss: 1.0221 - val_accuracy: 0.5289\n",
            "Epoch 34/200\n",
            "40/40 [==============================] - 2s 48ms/step - loss: 1.1459 - accuracy: 0.4766 - val_loss: 1.0204 - val_accuracy: 0.5305\n",
            "Epoch 35/200\n",
            "40/40 [==============================] - 2s 48ms/step - loss: 1.1243 - accuracy: 0.4689 - val_loss: 1.0196 - val_accuracy: 0.5305\n",
            "Epoch 36/200\n",
            "40/40 [==============================] - 2s 51ms/step - loss: 1.1348 - accuracy: 0.4715 - val_loss: 1.0200 - val_accuracy: 0.5297\n",
            "Epoch 37/200\n",
            "40/40 [==============================] - 2s 50ms/step - loss: 1.1245 - accuracy: 0.4808 - val_loss: 1.0186 - val_accuracy: 0.5305\n",
            "Epoch 38/200\n",
            "40/40 [==============================] - 2s 49ms/step - loss: 1.0985 - accuracy: 0.4859 - val_loss: 1.0173 - val_accuracy: 0.5305\n",
            "Epoch 39/200\n",
            "40/40 [==============================] - 2s 48ms/step - loss: 1.1176 - accuracy: 0.4742 - val_loss: 1.0177 - val_accuracy: 0.5305\n",
            "Epoch 40/200\n",
            "40/40 [==============================] - 2s 49ms/step - loss: 1.0980 - accuracy: 0.4849 - val_loss: 1.0167 - val_accuracy: 0.5305\n",
            "Epoch 41/200\n",
            "40/40 [==============================] - 2s 62ms/step - loss: 1.0855 - accuracy: 0.4988 - val_loss: 1.0173 - val_accuracy: 0.5297\n",
            "Epoch 42/200\n",
            "40/40 [==============================] - 2s 48ms/step - loss: 1.0851 - accuracy: 0.5049 - val_loss: 1.0177 - val_accuracy: 0.5289\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYK365TCky7s"
      },
      "source": [
        "with strategy.scope():\r\n",
        "  model.layers[0].trainable = True\r\n",
        "  optimizer = tf.keras.optimizers.Adam(lr=1e-6)\r\n",
        "  model.compile(optimizer = optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0yzQP6dlNj5",
        "outputId": "8c670516-047a-4ca2-97a8-1acec6b5b4e2"
      },
      "source": [
        "epochs_done = 42\r\n",
        "history = model.fit(\r\n",
        "  train_dataset,\r\n",
        "  epochs = 200,\r\n",
        "  steps_per_epoch = STEPS,\r\n",
        "  callbacks = [early],\r\n",
        "  validation_data = val_dataset,\r\n",
        "  initial_epoch = epochs_done,\r\n",
        "  workers = 8,\r\n",
        "  use_multiprocessing = True\r\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 43/200\n",
            "40/40 [==============================] - 74s 232ms/step - loss: 1.0987 - accuracy: 0.4724 - val_loss: 1.0224 - val_accuracy: 0.5227\n",
            "Epoch 44/200\n",
            "40/40 [==============================] - 4s 99ms/step - loss: 1.0951 - accuracy: 0.4852 - val_loss: 1.0070 - val_accuracy: 0.5258\n",
            "Epoch 45/200\n",
            "40/40 [==============================] - 4s 98ms/step - loss: 1.0633 - accuracy: 0.4974 - val_loss: 1.0171 - val_accuracy: 0.5289\n",
            "Epoch 46/200\n",
            "40/40 [==============================] - 4s 97ms/step - loss: 1.0483 - accuracy: 0.4950 - val_loss: 1.0154 - val_accuracy: 0.5266\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmhPsP6pqAxr"
      },
      "source": [
        "model.save_pretrained(f\"weights/{MODEL}/nopreproc\")"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRtgnphInxP7"
      },
      "source": [
        "## Evaluation du modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwmb8woxpUUh"
      },
      "source": [
        "train_dataset = (\r\n",
        "    tf.data.Dataset\r\n",
        "    .from_tensor_slices((\r\n",
        "        tf.concat([x_train, x_val], axis = 0),\r\n",
        "        np.concatenate([y_train, y_val])\r\n",
        "      ))\r\n",
        "    .repeat()\r\n",
        "    .shuffle(BUFFER)\r\n",
        "    .batch(BATCH_D)\r\n",
        "    .prefetch(AUTO)\r\n",
        ")"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD9m2fcno0zN",
        "outputId": "8cbf9ca2-e590-45c5-95ed-37bf209a21b5"
      },
      "source": [
        "with strategy.scope():\r\n",
        "  final_model_1 = Camembert.from_pretrained(f\"weights/{MODEL}\")\r\n",
        "  final_model_1.layers[0].trainable = False\r\n",
        "  optimizer = tf.keras.optimizers.Adam(lr=1e-5)\r\n",
        "  final_model_1.compile(optimizer = optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "epochs_done = 0\r\n",
        "history = final_model_1.fit(\r\n",
        "  train_dataset,\r\n",
        "  epochs = 42,\r\n",
        "  steps_per_epoch = STEPS,\r\n",
        "  initial_epoch = epochs_done,\r\n",
        "  workers = 8, verbose = 0,\r\n",
        "  use_multiprocessing = True\r\n",
        ")\r\n",
        "\r\n",
        "with strategy.scope():\r\n",
        "  final_model_1.layers[0].trainable = True\r\n",
        "  optimizer = tf.keras.optimizers.Adam(lr=1e-6)\r\n",
        "  final_model_1.compile(optimizer = optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "epochs_done = 42\r\n",
        "history = final_model_1.fit(\r\n",
        "  train_dataset,\r\n",
        "  epochs = 4,\r\n",
        "  steps_per_epoch = STEPS,\r\n",
        "  initial_epoch = epochs_done,\r\n",
        "  workers = 8, verbose = 0,\r\n",
        "  use_multiprocessing = True\r\n",
        ")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing Camembert.\n",
            "\n",
            "All the layers of Camembert were initialized from the model checkpoint at weights/cam_base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use Camembert for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCoiybRJo3rL"
      },
      "source": [
        "pred_1 = final_model_1.predict(x_test)\r\n",
        "y_1 = encoder.inverse_transform(np.argmax(pred_1, axis = 1))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVI2Z5kOteSS"
      },
      "source": [
        "binarizer = LabelBinarizer()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQj20u8lsPEw",
        "outputId": "21106461-7cdb-46ff-b21f-0b714925137f"
      },
      "source": [
        "print(classification_report(test.label, y_1))\r\n",
        "\r\n",
        "print(\"F1-score: {}\\nAUC: {}\\nAccuracy: {}\".format(\r\n",
        "    f1_score(test.label, y_1, average = \"macro\"),\r\n",
        "    roc_auc_score(binarizer.fit_transform(y_test), pred_1, average = \"macro\", multi_class = \"ovr\"),\r\n",
        "    accuracy_score(test.label, y_1)\r\n",
        "))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     EMOTION       0.00      0.00      0.00       337\n",
            " INFORMATION       0.45      1.00      0.62      1473\n",
            "     OPINION       0.18      0.00      0.00       950\n",
            "   SENTIMENT       0.00      0.00      0.00       523\n",
            "\n",
            "    accuracy                           0.45      3283\n",
            "   macro avg       0.16      0.25      0.16      3283\n",
            "weighted avg       0.25      0.45      0.28      3283\n",
            "\n",
            "F1-score: 0.15583510327427194\n",
            "AUC: 0.5295628692569901\n",
            "Accuracy: 0.4480657934815717\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDrLVED1vfWC"
      },
      "source": [
        "# Modèle avec prétraitement mais sans Lem-Stem\r\n",
        "Données classic_nos_nol"
      ]
    }
  ]
}