{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Génération de texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import callbacks, layers, backend as K\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_label(datasetBatch):\n",
    "\n",
    "    def split_input_target(chunk):\n",
    "        \"\"\" from https://www.tensorflow.org/tutorials/text/text_generation \"\"\"\n",
    "        input_text = chunk[:-1]\n",
    "        target_text = chunk[1:]\n",
    "        return input_text, target_text\n",
    "\n",
    "    dataset_split = datasetBatch.map(split_input_target)\n",
    "    return dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitements préliminaires sur les données\n",
    "Le texte utilisé en apprentissage ici sera un texte de Shakespeare\n",
    "## Observation du vocabulaire\n",
    "Créer une fonction `get_vocab` qui retourne l’ensemble des caractères (uniques) présent dans le texte.  \n",
    "Afficher les caractères et le nombre de caractères."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab: ['\\n' ' ' '!' '$' '&' \"'\" ',' '-' '.' '3' ':' ';' '?' 'A' 'B' 'C' 'D' 'E'\n",
      " 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W'\n",
      " 'X' 'Y' 'Z' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o'\n",
      " 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n",
      "Length: 65\n"
     ]
    }
   ],
   "source": [
    "def get_vocab(text):\n",
    "    return np.unique(list(text))\n",
    "print(f\"Vocab: {get_vocab(text)}\\nLength: {len(get_vocab(text))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion du texte en entiers\n",
    "Créer une fonction `text2int` qui convertit le texte en une séquence d’entiers. A chaque caractère est associé un entier entre 0 et le nombre de caractères. Pour cela, créer un dictionnaire associant chaque caractère à un entier. La fonction retourne une liste contenant la séquence d’entiers et le dictionnaire permettant la conversion.\n",
    "\n",
    "Afficher les 45 premiers caractères du texte et les premiers entiers associés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 'First Citizen:\\nBefore we proceed any further,'\n",
      "Map: [6, 13, 17, 18, 19, 1, 5, 13, 19, 13, 23, 10, 14, 3, 0, 4, 10, 11, 15, 17, 10, 1, 21, 10, 1, 16, 17, 15, 8, 10, 10, 9, 1, 7, 14, 22, 1, 11, 20, 17, 19, 12, 10, 17, 2]\n"
     ]
    }
   ],
   "source": [
    "def text2int(text):\n",
    "    vocab = get_vocab(text)\n",
    "    mapping = {k:v for v,k in enumerate(vocab)}\n",
    "    mapped = [mapping[i] for i in list(text)]\n",
    "    return mapping, mapped\n",
    "\n",
    "print(f\"Text: {repr(text[:45])}\\nMap: {text2int(text[:45])[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construire un dictionnaire réalisant la conversion inverse du dictionnaire précédent : il a pour clé les entiers et pour valeur les caractères associés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2text = {v:k for k,v in text2int(text)[0].items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatage des données\n",
    "construire une fonction `create_examples` qui réalise les opérations suivantes:\n",
    "\n",
    "- Création d’un objet Dataset à partir d’une liste d’entiers donnée en argument.\n",
    "- Retourne des exemples de longueurs `seq_length`, où `seq_length` est un argument de la fonction valant par défaut 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_examples(data, seq_length = 100):\n",
    "    dataset = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices(data)\n",
    "        .batch(seq_length, drop_remainder = True)\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des entrées et labels\n",
    "La tâche ici sera d’entraîner le réseau à prédire le caractère suivant. La fonction `create_input_label` réalise un découpage de chaque exemple du batch pour construire l’entrée du réseau et son label associé. Ainsi :\n",
    "\n",
    "- l’entrée est l’ensemble des caractères de la séquence sauf le dernier (le dernier caractère n’est pas une entrée du réseau puisqu’il s’agit du dernier élément à prédire)\n",
    "- le label est l’ensemble des caractères de la séquence sauf le premier (le premier étant l’entrée initiale du réseau, le premier élément prédit est le second caractère)\n",
    "\n",
    "Appliquer la fonction `create_input_label` sur la sortie de la question précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapdata = create_input_label(create_examples(text2int(text)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant la méthode `take` applicable sur un objet `Dataset`, afficher pour les 3 premiers exemples les séquences d’entrée et de label.  Il faudra pour cela convertir les tenseurs en numpy de la forme `monTenseur.numpy()`. Utiliser le dictionnaire de conversion approprié pour que ce soit un affichage de phrases en caractères."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Input: 'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYo'\n",
      " Label: 'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
      "--------------------------------------------------------------------------------\n",
      " Input: ' are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, yo'\n",
      " Label: 'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you'\n",
      "--------------------------------------------------------------------------------\n",
      " Input: \" know Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet u\"\n",
      " Label: \"know Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us\"\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for x,y in mapdata.take(3):\n",
    "    print(f\" Input: {repr(''.join(int2text[i] for i in x.numpy()))}\")\n",
    "    print(f\" Label: {repr(''.join(int2text[i] for i in y.numpy()))}\")\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de batchs d’apprentissage\n",
    "Découper les exemples créés à la question précédente en batch. La fonction `create_batch` prendra en argument le nombre d’exemples dans les batchs qui vaudra par défaut 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch(data, batch_size = 64):\n",
    "    return data.batch(batch_size, drop_remainder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "VOCAB_SIZE = len(get_vocab(text))\n",
    "SEQ_LENGTH = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction du modèle\n",
    "## Définition de l’architecture\n",
    "Créer une fonction `model_rnn` pour construire le modèle suivant de façon fonctionnelle :\n",
    "\n",
    "- Définir une couche d’entrée dont les entrées sont de dimension (batch_size, seq_length) donnés en argument de la fonction.\n",
    "- Construire une couche d’Embedding réalisant une projection des données d’entrée endimension 256.\n",
    "- Construire une couche SimpleRNN de 512 unités prenant en entrée le tenseur issu de la couche d’embedding. Attention, la couche récurrente doit retourner une séquence(une sortie par entrée).\n",
    "- Construire une couche totalement connectée (Dense) ayant autant d’unités que de labels possibles et prenant en entrée la sortie de la couche récurrente.\n",
    "- Définir le modèle Keras (Model) issu de l’architecture décrite ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rnn(batch_size, seq_length, vocab_size):\n",
    "    input_layer = layers.Input(batch_input_shape = (batch_size, seq_length))\n",
    "    x = layers.Embedding(vocab_size, 256)(input_layer)\n",
    "    x = layers.SimpleRNN(512, return_sequences = True)(x)\n",
    "    x = layers.Dense(vocab_size)(x)\n",
    "    return Model(inputs = input_layer, outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(64, 100)]               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (64, 100, 256)            16640     \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (64, 100, 512)            393728    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, 100, 65)             33345     \n",
      "=================================================================\n",
      "Total params: 443,713\n",
      "Trainable params: 443,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model1 = model_rnn(BATCH_SIZE, SEQ_LENGTH, VOCAB_SIZE)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition de la fonction de coût (loss)\n",
    "Construire une fonction loss retournant le résultat de l’entropie croisée dans un cadre d’application multiclasse. La fonction doit avoir deux arguments:\n",
    "\n",
    "- Les labels associés aux observations (i.e. les entiers associés aux caractères)\n",
    "- Les logits, la sortie du réseau (i.e. les probabilités de chaque caractère)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(labels, logits):\n",
    "    return keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération du texte\n",
    "La fonction `generate_text` a pour but de générer du texte à partir d’une séquence donnée en entrée (start_string).  \n",
    "Ici chaque caractère va être généré de manière itérative (un par un). On va augmenter la séquence d’entrée avec le dernier caractère prédit pour prédire le caractère suivant.\n",
    "\n",
    "- Convertir la chaîne de caractère d’entrée en nombres et stocker le résultat dans la variable `input_eval`.\n",
    "- Convertir l’entier prédit en caractère.\n",
    "- Stocker successivement les différents caractères prédits et retourner la séquence complète."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, char2idx, idx2char, num2generate=1000):\n",
    "\n",
    "    input_eval = [char2idx[x] for x in list(start_string)]\n",
    "    eval_tensor = tf.expand_dims(input_eval, 0)\n",
    "    text = []\n",
    "    for i in range(num2generate):\n",
    "        pred_tensor = model.predict(eval_tensor)\n",
    "        pred_tensor = tf.squeeze(pred_tensor, 0)  # suppression de la dimension du batch\n",
    "        predicted_int = tf.random.categorical(pred_tensor, num_samples=1)[\n",
    "            -1, 0].numpy()  # conversion du dernier caractère prédit en valeur numpy\n",
    "        eval_tensor = tf.expand_dims([predicted_int], 0)  # nouvelle entrée pour la future prédiction\n",
    "        text.append(idx2char[predicted_int])\n",
    "    return ''.join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage du réseau et prédiction\n",
    "Compiler le modèle en utilisant l’optimiseur Adam et la fonction de coût (loss) définie précédemment.  \n",
    "Ecrire une ligne de commande utilisant la fonction `fit` d’un modèle Keras afin de réaliser l’apprentissage du modèle sur 5 epochs.  \n",
    "Ecrire une ligne de commande récupérant la séquence de prédictions issue de la fonction `generate_text` pour la séquence d’entrée de votre choix.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model1.compile(\n",
    "        loss=loss_function,\n",
    "        optimizer='adam'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Model was constructed with shape (64, 100) for input Tensor(\"input_1:0\", shape=(64, 100), dtype=float32), but it was called on an input with incompatible shape (64, 99).\n",
      "WARNING:tensorflow:Model was constructed with shape (64, 100) for input Tensor(\"input_1:0\", shape=(64, 100), dtype=float32), but it was called on an input with incompatible shape (64, 99).\n",
      "174/174 [==============================] - 8s 48ms/step - loss: 2.7711\n",
      "Epoch 2/5\n",
      "174/174 [==============================] - 8s 48ms/step - loss: 2.1878\n",
      "Epoch 3/5\n",
      "174/174 [==============================] - 8s 48ms/step - loss: 2.0171\n",
      "Epoch 4/5\n",
      "174/174 [==============================] - 9s 49ms/step - loss: 1.8938\n",
      "Epoch 5/5\n",
      "174/174 [==============================] - 8s 47ms/step - loss: 1.8008\n"
     ]
    }
   ],
   "source": [
    "dataset = create_batch(create_input_label(create_examples(text2int(text)[1])))\n",
    "with tf.device('/gpu:0'):\n",
    "    hist1 = model1.fit(\n",
    "        dataset,\n",
    "        epochs = 5,\n",
    "        verbose = 1,\n",
    "        use_multiprocessing = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Améliorer son réseau\n",
    "- Remplacer la couche SimpleRNN par une couche GRU\n",
    "- Ajouter une 2ème couche récurrente avant la couche Dense\n",
    "- Modifier votre fonction `model_rnn` en spécifiant que certaines dimensions ne sont pas précisée (valeur `None`)\n",
    "- Doubler la taille des couches récurrentes\n",
    "- Ajouter du dropout dans votre réseau\n",
    "- Augmenter le nombre d’epochs\n",
    "- Mettre `stateful = True` sur les couches récurrentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rnn(embedding, batch_size, vocab_size):\n",
    "    input_layer = layers.Input(batch_input_shape = (batch_size, None))\n",
    "    x = layers.Embedding(vocab_size, embedding)(input_layer)\n",
    "    x = layers.Dropout(.1)(x)\n",
    "    x = layers.GRU(100, stateful = True, return_sequences = True)(x)\n",
    "    x = layers.Dropout(.2)(x)\n",
    "    x = layers.GRU(100, stateful = True, return_sequences = True)(x)\n",
    "    x = layers.Dropout(.2)(x)\n",
    "    x = layers.Dense(vocab_size)(x)\n",
    "    return Model(inputs = input_layer, outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(64, None)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (64, None, 512)           33280     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (64, None, 512)           0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (64, None, 100)           184200    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (64, None, 100)           0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (64, None, 100)           60600     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (64, None, 100)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (64, None, 65)            6565      \n",
      "=================================================================\n",
      "Total params: 284,645\n",
      "Trainable params: 284,645\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "174/174 [==============================] - 4s 25ms/step - loss: 2.8011\n",
      "Epoch 2/5\n",
      "174/174 [==============================] - 4s 25ms/step - loss: 2.2422\n",
      "Epoch 3/5\n",
      "174/174 [==============================] - 4s 26ms/step - loss: 2.0894\n",
      "Epoch 4/5\n",
      "174/174 [==============================] - 4s 24ms/step - loss: 1.9978\n",
      "Epoch 5/5\n",
      "174/174 [==============================] - 4s 25ms/step - loss: 1.9344\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model2 = model_rnn(512, BATCH_SIZE, VOCAB_SIZE)\n",
    "    model2.compile(\n",
    "        loss=loss_function,\n",
    "        optimizer='adam'\n",
    "    )\n",
    "    model2.summary()\n",
    "    hist2 = model2.fit(\n",
    "        dataset,\n",
    "        epochs = 5,\n",
    "        verbose = 1,\n",
    "        use_multiprocessing = True\n",
    "    )\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
